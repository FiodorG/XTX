{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import pickle\n",
    "import scipy\n",
    "import warnings\n",
    "import functools\n",
    "import pyearth\n",
    "import scipy\n",
    "import numpy as np\n",
    "import ipywidgets as pyw\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score, explained_variance_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, HuberRegressor, BayesianRidge, RidgeCV, Perceptron, Lasso, LassoCV, SGDRegressor\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, TimeSeriesSplit, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_decomposition import PLSCanonical, PLSRegression, CCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "pd.set_option('display.max_columns', 61)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "np.set_printoptions(precision=5)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def pretty_print_2d(line, matrix):\n",
    "    print(line)\n",
    "    s = [[str(e) for e in row] for row in matrix]\n",
    "    lens = [max(map(len, col)) for col in zip(*s)]\n",
    "    fmt = '\\t'.join('{{:{}}}'.format(x) for x in lens)\n",
    "    table = [fmt.format(*row) for row in s]\n",
    "    print('\\n'.join(table))\n",
    "\n",
    "\n",
    "def display_2d_relationship(df, sig1, sig2, n_quantiles = 10):\n",
    "\n",
    "    dft = df[['y', sig1, sig2]]\n",
    "    dft['sig1_decile'] = pd.qcut(dft[sig1], q=n_quantiles, duplicates='drop', precision=3)\n",
    "    dft['sig2_decile'] = pd.qcut(dft[sig2], q=n_quantiles, duplicates='drop', precision=3)\n",
    "\n",
    "    results = np.zeros((n_quantiles, n_quantiles))\n",
    "\n",
    "    for i, sig1_dec in enumerate(dft.sig1_decile.unique()):\n",
    "        t = dft[dft.sig1_decile == sig1_dec].copy()\n",
    "        for j, sig2_dec in enumerate(dft.sig2_decile.unique()):\n",
    "            results[i, j] = np.mean(t[t.sig2_decile == sig2_dec].y)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    cax = ax.matshow(results, origin='upper')\n",
    "    ax.set_xlabel(sig1)\n",
    "    ax.set_ylabel(sig2)\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticks(range(n_quantiles))\n",
    "    ax.set_xticklabels(['Dec%i' % i for i in range(1, n_quantiles + 1)], rotation=45)\n",
    "    ax.set_yticks(range(n_quantiles))\n",
    "    ax.set_yticklabels(['Dec%i' % i for i in range(n_quantiles, 0, -1)], rotation=45)\n",
    "\n",
    "    X = np.arange(1, n_quantiles + 1)\n",
    "    Y = np.arange(1, n_quantiles + 1)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    surf = ax.plot_surface(Y, X, results, cmap='hot')\n",
    "    ax.set_xlabel(sig2)\n",
    "    ax.set_ylabel(sig1)\n",
    "    ax.set_zlabel('y')\n",
    "    plt.colorbar(surf)\n",
    "    ax.set_xticks(range(1, n_quantiles + 1))\n",
    "    ax.set_xticklabels(['%i' % i for i in range(1, n_quantiles + 1)])\n",
    "    ax.set_yticks(range(1, n_quantiles + 1))\n",
    "    ax.set_yticklabels(['%i' % i for i in range(1, n_quantiles + 1)])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pretty_print_dict(d):\n",
    "    for key, value in d.items():\n",
    "        print('%30s: ' % str(key) + str(['%.6f' % x for x in value]))\n",
    "\n",
    "\n",
    "def cross_validate_custom(estimator, X, y, w, sig, cv=TimeSeriesSplit(n_splits=3)):\n",
    "    \n",
    "    scores = (_fit_and_score(copy.deepcopy(estimator), X, y, w, sig, train, test) for train, test in cv.split(X, y))\n",
    "    scores = list(zip(*scores))\n",
    "    \n",
    "    return {\n",
    "        'train_score': np.array(scores[0]),\n",
    "        'test_score': np.array(scores[1]),\n",
    "        'coefficients': np.array(scores[2])\n",
    "    }\n",
    "\n",
    "\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "\n",
    "def plot_regression(df, sig, w=None, model=LinearRegression(fit_intercept=False), plot=False, print_output=True):\n",
    "    \n",
    "    x = df[sig]\n",
    "    y = df.y\n",
    "    \n",
    "    if w is None:\n",
    "        w = df.y * 0 + 1\n",
    "\n",
    "    scores = cross_validate_custom(model, x, y, w, sig)\n",
    "    \n",
    "    x, y, w = _clean_x_y(x, y, w, sig)\n",
    "    \n",
    "    try:\n",
    "        model.fit(x, y, w_train)\n",
    "    except:\n",
    "        model.fit(x, y)\n",
    "    \n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    if print_output:\n",
    "        print('Model:       %s' % str(model))\n",
    "        print('Signal:      %s' % sig)\n",
    "        print('Train score: %s' % scores['train_score'])\n",
    "        print('Test score:  %s' % scores['test_score'])\n",
    "        print('R2 Total:    %.6f' % r2_score(y, y_pred))\n",
    "        print('Signal mean: %s' % x.mean().values)\n",
    "        if len(sig) == 1:\n",
    "            print('Signal !=0:  %s' % len(x[x[sig] != 0]))\n",
    "\n",
    "        if hasattr(model, 'coef_'):\n",
    "            pretty_print_2d('Coefficients CV:', scores['coefficients'])\n",
    "            pretty_print_2d('Coefficients:', [model.coef_])\n",
    "\n",
    "        print('')\n",
    "\n",
    "    if len(sig) == 1 and plot:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
    "        axs[0].plot(x, y, '+')\n",
    "        axs[0].plot(x, y_pred, 'r-')\n",
    "        axs[0].set_xlabel('signal')\n",
    "        axs[0].set_ylabel('y')\n",
    "\n",
    "        dft = df[[sig[0], 'y']]\n",
    "        dft['signal decile'] = pd.qcut(dft[sig[0]], q=np.linspace(0, 1., 31), duplicates='drop', precision=3)\n",
    "        axs[1] = sns.barplot(x='signal decile', y='y', data=dft, ci=None, palette='Spectral')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    return scores['test_score']\n",
    "\n",
    "\n",
    "def _clean_x_y(X, y, w, sig):\n",
    "    \n",
    "#     indices_x = (X.vol_y <= 0.8)\n",
    "#     indices_y = (X.vol_y <= 99999)\n",
    "    \n",
    "#     X = X[indices_x & indices_y]\n",
    "#     y = y[indices_x & indices_y]\n",
    "#     w = w[indices_x & indices_y]\n",
    "    \n",
    "    return X, y, w\n",
    "\n",
    "\n",
    "def _fit_and_score(estimator, X, y, w, sig, train, test):\n",
    "\n",
    "    X_train = X.iloc[train]\n",
    "    y_train = y.iloc[train]\n",
    "    w_train = w.iloc[train]\n",
    "    \n",
    "    X_train, y_train, w_train = _clean_x_y(X_train, y_train, w_train, sig)\n",
    "    \n",
    "    X_test = X.iloc[test]\n",
    "    y_test = y.iloc[test]\n",
    "    \n",
    "    try:\n",
    "        estimator.fit(X_train, y_train, w_train)\n",
    "    except:\n",
    "        estimator.fit(X_train, y_train)\n",
    "\n",
    "    train_score = r2_score(y_train, estimator.predict(X_train))\n",
    "    test_score = r2_score(y_test, estimator.predict(X_test))\n",
    "    \n",
    "    result = [train_score, test_score]\n",
    "    \n",
    "    if hasattr(estimator, 'coef_'):\n",
    "        result.append(estimator.coef_)\n",
    "    else:\n",
    "        result.append(0)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def test_signal(df, signal, model=LinearRegression(fit_intercept=False)):\n",
    "    df['sig'] = df[signal]\n",
    "    df['sig_cubed'] = df[signal]**3\n",
    "    df['sig_shift10'] = df[signal].shift(10).fillna(0)\n",
    "    df['sig_shift50'] = df[signal].shift(50).fillna(0)\n",
    "    df['sig_diff'] = df[signal].diff(1).fillna(0)\n",
    "    df['sig_ewm'] = df[signal].ewm(span=200, adjust=False).mean()\n",
    "    df['sig_macd'] = df[signal].ewm(span=200, adjust=False).mean() - df[signal].ewm(span=1000, adjust=False).mean()\n",
    "    df['sig_1'] = df['sig'] - df['sig_ewm']\n",
    "    df['sig_2'] = ((df['sig'] - df['sig_ewm']) / df['sig_ewm']).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_3'] = ((df['sig'] - df[signal].ewm(span=20, adjust=False).mean()) / df[signal].ewm(span=20, adjust=False).std()).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_4'] = ((df['sig'] - df[signal].ewm(span=50, adjust=False).mean()) / df[signal].ewm(span=50, adjust=False).std()).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_5'] = ((df['sig'] - df[signal].ewm(span=100, adjust=False).mean()) / df[signal].ewm(span=100, adjust=False).std()).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_6'] = ((df['sig'] - df[signal].ewm(span=200, adjust=False).mean()) / df[signal].ewm(span=200, adjust=False).std()).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_7'] = ((df['sig'] - df[signal].ewm(span=500, adjust=False).mean()) / df[signal].ewm(span=500, adjust=False).std()).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_8'] = ((df['sig'] - df[signal].ewm(span=1000, adjust=False).mean()) / df[signal].ewm(span=1000, adjust=False).std()).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_9'] = ((df['sig'] - df[signal].ewm(span=1500, adjust=False).mean()) / df[signal].ewm(span=1500, adjust=False).std()).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "    results_sig = plot_regression(df, ['sig'], model=model, plot=False, print_output=False)\n",
    "    results_sig_nonzero = plot_regression(df[df['sig'] != 0], ['sig'], model=model, plot=False, print_output=False)\n",
    "    results_sig_cubed = plot_regression(df, ['sig_cubed'], model=model, plot=False, print_output=False)\n",
    "    results_sig_shift10 = plot_regression(df, ['sig_shift10'], model=model, plot=False, print_output=False)\n",
    "    results_sig_shift50 = plot_regression(df, ['sig_shift50'], model=model, plot=False, print_output=False)\n",
    "    results_sig_diff = plot_regression(df, ['sig_diff'], model=model, plot=False, print_output=False)\n",
    "    results_sig_ewm = plot_regression(df, ['sig_ewm'], model=model, plot=False, print_output=False)\n",
    "    results_sig_macd = plot_regression(df, ['sig_macd'], model=model, plot=False, print_output=False)\n",
    "    results_sig_1 = plot_regression(df, ['sig_1'], model=model, plot=False, print_output=False)\n",
    "    results_sig_2 = plot_regression(df, ['sig_2'], model=model, plot=False, print_output=False)\n",
    "    results_sig_3 = plot_regression(df, ['sig_3'], model=model, plot=False, print_output=False)\n",
    "    results_sig_4 = plot_regression(df, ['sig_4'], model=model, plot=False, print_output=False)\n",
    "    results_sig_5 = plot_regression(df, ['sig_5'], model=model, plot=False, print_output=False)\n",
    "    results_sig_6 = plot_regression(df, ['sig_6'], model=model, plot=False, print_output=False)\n",
    "    results_sig_7 = plot_regression(df, ['sig_7'], model=model, plot=False, print_output=False)\n",
    "    results_sig_8 = plot_regression(df, ['sig_8'], model=model, plot=False, print_output=False)\n",
    "    results_sig_9 = plot_regression(df, ['sig_9'], model=model, plot=False, print_output=False)\n",
    "    \n",
    "    results = {\n",
    "        'Signal': results_sig,\n",
    "        'Signal Non Zero': results_sig_nonzero,\n",
    "        'Signal Cubed': results_sig_cubed,\n",
    "        'Signal Shift10': results_sig_shift10,\n",
    "        'Signal Shift50': results_sig_shift50,\n",
    "        'Signal diff': results_sig_diff,\n",
    "        'Signal EWM': results_sig_ewm,\n",
    "        'Signal MACD': results_sig_macd,\n",
    "        'Signal - EWM': results_sig_1,\n",
    "        'Signal - EWM / EWM': results_sig_2,\n",
    "        'Signal ZScore 20': results_sig_3,\n",
    "        'Signal ZScore 50': results_sig_4,\n",
    "        'Signal ZScore 100': results_sig_5,\n",
    "        'Signal ZScore 200': results_sig_6,\n",
    "        'Signal ZScore 500': results_sig_7,\n",
    "        'Signal ZScore 1000': results_sig_8,\n",
    "        'Signal ZScore 1500': results_sig_9,\n",
    "    }\n",
    "    \n",
    "    print('Signal: %s' % signal)\n",
    "    pretty_print_dict(results)\n",
    "\n",
    "#     plot_correl(df, ['sig', 'sig_cubed', 'sig_shift10', 'sig_shift50', 'sig_diff', 'sig_ewm', 'sig_macd', 'sig_1', 'sig_2', 'sig_3', 'sig_4', 'sig_5', 'sig_6', 'sig_7', 'sig_8', 'sig_9'], method='pearson')\n",
    "\n",
    "    \n",
    "def test_double_signal(df, signal1, signal2, model=LinearRegression(fit_intercept=False)):\n",
    "    df['sig1t'] = df[signal1].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig2t'] = df[signal2].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_diff'] = (df[signal1] - df[signal2]).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_cursor'] = ((df[signal1] - df[signal2]) / (df[signal1] + df[signal2])).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_cursor_cubed'] = (df['sig_cursor']**3).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_cursor_clipped'] = (np.clip(df['sig_cursor'], -3., 3.)).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "    df['sig_diff_ewm_10'] = (df[signal1].ewm(span=10, adjust=False).mean() - df[signal2].ewm(span=10, adjust=False).mean()).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_diff_ewm_20'] = (df[signal1].ewm(span=20, adjust=False).mean() - df[signal2].ewm(span=20, adjust=False).mean()).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_diff_ewm_50'] = (df[signal1].ewm(span=50, adjust=False).mean() - df[signal2].ewm(span=50, adjust=False).mean()).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_diff_ewm_100'] = (df[signal1].ewm(span=100, adjust=False).mean() - df[signal2].ewm(span=100, adjust=False).mean()).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_diff_ewm_200'] = (df[signal1].ewm(span=200, adjust=False).mean() - df[signal2].ewm(span=200, adjust=False).mean()).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "    df['sig_cursor_ewm_20'] = ((df[signal1].ewm(span=20, adjust=False).mean() - df[signal2].ewm(span=20, adjust=False).mean()) / (df[signal1].ewm(span=20, adjust=False).mean() + df[signal2].ewm(span=20, adjust=False).mean())).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_cursor_ewm_50'] = ((df[signal1].ewm(span=50, adjust=False).mean() - df[signal2].ewm(span=50, adjust=False).mean()) / (df[signal1].ewm(span=50, adjust=False).mean() + df[signal2].ewm(span=50, adjust=False).mean())).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_cursor_ewm_100'] = ((df[signal1].ewm(span=100, adjust=False).mean() - df[signal2].ewm(span=100, adjust=False).mean()) / (df[signal1].ewm(span=100, adjust=False).mean() + df[signal2].ewm(span=100, adjust=False).mean())).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['sig_cursor_ewm_200'] = ((df[signal1].ewm(span=200, adjust=False).mean() - df[signal2].ewm(span=200, adjust=False).mean()) / (df[signal1].ewm(span=200, adjust=False).mean() + df[signal2].ewm(span=200, adjust=False).mean())).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "    df['sig_zscore_diff_20'] = z_score(df[signal1] - df[signal2], 20)\n",
    "    df['sig_zscore_diff_50'] = z_score(df[signal1] - df[signal2], 50)\n",
    "    df['sig_zscore_diff_100'] = z_score(df[signal1] - df[signal2], 100)\n",
    "    \n",
    "    df['sig_zscore_cursor'] = z_score((df[signal1] - df[signal2]) / (df[signal1] + df[signal2]), 20)\n",
    "    \n",
    "    df['sig_diff_zscore_10'] = z_score(df[signal1], 10) - z_score(df[signal2], 10)\n",
    "    df['sig_diff_zscore_20'] = z_score(df[signal1], 20) - z_score(df[signal2], 20)\n",
    "    df['sig_diff_zscore_50'] = z_score(df[signal1], 50) - z_score(df[signal2], 50)\n",
    "    df['sig_diff_zscore_100'] = z_score(df[signal1], 100) - z_score(df[signal2], 100)\n",
    "    df['sig_diff_zscore_200'] = z_score(df[signal1], 200) - z_score(df[signal2], 200)\n",
    "    \n",
    "    results = {\n",
    "        'Sig1': plot_regression(df, ['sig1t'], model=model, plot=False, print_output=False),\n",
    "        'Sig2': plot_regression(df, ['sig2t'], model=model, plot=False, print_output=False),\n",
    "        'Sig Diff': plot_regression(df, ['sig_diff'], model=model, plot=False, print_output=False),\n",
    "        'Sig Cursor': plot_regression(df, ['sig_cursor'], model=model, plot=False, print_output=False),\n",
    "        'Sig Cursor Cubed': plot_regression(df, ['sig_cursor_cubed'], model=model, plot=False, print_output=False),\n",
    "        'Sig Cursor Clipped': plot_regression(df, ['sig_cursor_clipped'], model=model, plot=False, print_output=False),\n",
    "        'Sig Diff EWM 10': plot_regression(df, ['sig_diff_ewm_10'], model=model, plot=False, print_output=False),\n",
    "        'Sig Diff EWM 20': plot_regression(df, ['sig_diff_ewm_20'], model=model, plot=False, print_output=False),\n",
    "        'Sig Diff EWM 50': plot_regression(df, ['sig_diff_ewm_50'], model=model, plot=False, print_output=False),\n",
    "        'Sig Diff EWM 100': plot_regression(df, ['sig_diff_ewm_100'], model=model, plot=False, print_output=False),\n",
    "        'Sig Diff EWM 200': plot_regression(df, ['sig_diff_ewm_200'], model=model, plot=False, print_output=False),\n",
    "        'Sig Cursor EWM 20': plot_regression(df, ['sig_cursor_ewm_20'], model=model, plot=False, print_output=False),\n",
    "        'Sig Cursor EWM 50': plot_regression(df, ['sig_cursor_ewm_50'], model=model, plot=False, print_output=False),\n",
    "        'Sig Cursor EWM 100': plot_regression(df, ['sig_cursor_ewm_100'], model=model, plot=False, print_output=False),\n",
    "        'Sig Cursor EWM 200': plot_regression(df, ['sig_cursor_ewm_200'], model=model, plot=False, print_output=False),\n",
    "        'Sig ZScore Diff 20': plot_regression(df, ['sig_zscore_diff_20'], model=model, plot=False, print_output=False),\n",
    "        'Sig ZScore Diff 50': plot_regression(df, ['sig_zscore_diff_50'], model=model, plot=False, print_output=False),\n",
    "        'Sig ZScore Diff 100': plot_regression(df, ['sig_zscore_diff_100'], model=model, plot=False, print_output=False),\n",
    "        'Sig ZScore Cursor': plot_regression(df, ['sig_zscore_cursor'], model=model, plot=False, print_output=False),\n",
    "        'Sig Diff ZScore 10': plot_regression(df, ['sig_diff_zscore_10'], model=model, plot=False, print_output=False),\n",
    "        'Sig Diff ZScore 20': plot_regression(df, ['sig_diff_zscore_20'], model=model, plot=False, print_output=False),\n",
    "        'Sig Diff ZScore 50': plot_regression(df, ['sig_diff_zscore_50'], model=model, plot=False, print_output=False),\n",
    "        'Sig Diff ZScore 100': plot_regression(df, ['sig_diff_zscore_100'], model=model, plot=False, print_output=False),\n",
    "        'Sig Diff ZScore 200': plot_regression(df, ['sig_diff_zscore_200'], model=model, plot=False, print_output=False),\n",
    "    }\n",
    "    \n",
    "    print('Signal: %s %s' % (signal1, signal2))\n",
    "    pretty_print_dict(results)\n",
    "\n",
    "    plot_correl(df, ['sig1t','sig2t','sig_diff','sig_cursor','sig_cursor_cubed','sig_cursor_clipped','sig_diff_ewm_10','sig_diff_ewm_20','sig_diff_ewm_50','sig_diff_ewm_100','sig_diff_ewm_200',\n",
    "                    'sig_cursor_ewm_20','sig_cursor_ewm_50','sig_cursor_ewm_100','sig_cursor_ewm_200','sig_zscore_diff_20','sig_zscore_diff_50','sig_zscore_diff_100','sig_zscore_cursor',\n",
    "                     'sig_diff_zscore_10','sig_diff_zscore_20','sig_diff_zscore_50','sig_diff_zscore_100','sig_diff_zscore_200'], method='pearson')\n",
    "    \n",
    "\n",
    "def z_score(s, span):\n",
    "    return ((s - s.ewm(span=span, adjust=False).mean()) / s.ewm(span=span, adjust=False).std()).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "\n",
    "def plot_correl(df, signals, method='pearson'):\n",
    "    x = df[signals]\n",
    "    f = plt.figure(figsize=(19, 15))\n",
    "    corr = x.corr(method=method)\n",
    "    f, ax = plt.subplots(figsize=(9, 7))\n",
    "    sns.heatmap(corr, xticklabels=signals, yticklabels=signals, cmap=sns.diverging_palette(5, 250, as_cmap=True), annot=True, linewidths=.5, ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def group_by_levels(dft, show_trades=True, negative_ask=False):\n",
    "    y = dft.y.values.copy()\n",
    "    \n",
    "    bidask = 'bid'\n",
    "    dft_bid = dft[[x for x in dft.columns if bidask in x]].drop([bidask + 'SizeTotal'], axis=1).replace(0, np.nan)\n",
    "    dfts = [dft.pivot_table(values='%sSize%.0f' % (bidask, x), index=dft.index, columns='%sRate%.0f' % (bidask, x), aggfunc='first').reset_index().set_index('index').reindex(dft.index).reset_index() for x in range(0, 15)]\n",
    "    dft_bid = functools.reduce((lambda x, y: x.combine_first(y)), dfts)\n",
    "\n",
    "    bidask = 'ask'\n",
    "    dft_ask = dft[[x for x in dft.columns if bidask in x]].drop([bidask + 'SizeTotal'], axis=1).replace(0, np.nan)\n",
    "    dfts = [dft.pivot_table(values='%sSize%.0f' % (bidask, x), index=dft.index, columns='%sRate%.0f' % (bidask, x), aggfunc='first').reset_index().set_index('index').reindex(dft.index).reset_index() for x in range(0, 15)]\n",
    "    dft_ask = functools.reduce((lambda x, y: x.combine_first(y)), dfts)\n",
    "\n",
    "    if negative_ask:\n",
    "        dft = dft_bid.combine_first(-dft_ask)\n",
    "    else:\n",
    "        dft = dft_bid.combine_first(dft_ask)\n",
    "    dft.drop(['index'], axis=1, inplace=True)\n",
    "    dft = dft.reindex(sorted(dft.columns), axis=1)\n",
    "    \n",
    "    if show_trades:\n",
    "        dft = dft.fillna(0).diff(1).fillna(0)\n",
    "\n",
    "    dft['y'] = y\n",
    "    \n",
    "    return dft\n",
    "\n",
    "\n",
    "def plot_order_size(dft, only_size=False):\n",
    "    with plt.style.context(('dark_background')):\n",
    "        fig, ax1 = plt.subplots(figsize=(20, 16))\n",
    "\n",
    "        for col in dft.columns:\n",
    "            fil = np.abs(dft[col]) > 0\n",
    "            colors = ['#000000' if b==0 else '#00ffff' if b>0 else '#ff0000' for b in dft[fil][col]]\n",
    "            if only_size:\n",
    "                ax1.scatter(dft[fil].index, np.abs(dft[fil][col]), s=3, c=colors)\n",
    "            else:\n",
    "                ax1.scatter(dft[fil].index, dft[fil][col] * 0 + float(col), s=np.abs(dft[fil][col]), c=colors)\n",
    "\n",
    "        # ax1.yaxis.set_ticks(np.arange(0, 51, 1))\n",
    "        ax1.set_xlabel('timestamp')\n",
    "        ax1.set_ylabel('order size')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def test_signal_full(df, signal, signals, model=LinearRegression(fit_intercept=False)):\n",
    "    plot_regression(df, [signal], model=model)\n",
    "    test_signal(df, signal, model=model)\n",
    "    plot_correl(df, signals + [signal])\n",
    "    plot_regression(df, signals, model=model, plot=False)\n",
    "    plot_regression(df, signals + [signal], model=model, plot=False)\n",
    "\n",
    "\n",
    "def explain_error_vs_signal(df, signals, signal):\n",
    "    x = df[signals]\n",
    "    y = df.y\n",
    "    model = LinearRegression(fit_intercept=False, normalize=False)\n",
    "    model.fit(x, y)\n",
    "    df['y_hat'] = model.predict(x)\n",
    "    df['error'] = (df.y - df.y_hat)**2\n",
    "    \n",
    "    model = LinearRegression(fit_intercept=False, normalize=False)\n",
    "    model.fit(signal.values.reshape(-1, 1), df.error)\n",
    "    print(r2_score(df.error, model.predict(signal.values.reshape(-1, 1))))\n",
    "\n",
    "    df['indep decile'] = pd.qcut(signal, q=np.linspace(0, 1., 31), duplicates='drop', precision=3)\n",
    "    sns.barplot(x='indep decile', y='error', data=df, ci=None, palette='Spectral')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def add_nbr_trades(df):\n",
    "    bid_trd = np.zeros(len(df))\n",
    "    ask_trd = np.zeros(len(df))\n",
    "\n",
    "    i = 0\n",
    "    prev_row = df.iloc[0]\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        askRate0 = row.askRate0\n",
    "        bidRate0 = row.bidRate0\n",
    "        askSize0 = row.askSize0\n",
    "        bidSize0 = row.bidSize0\n",
    "\n",
    "        #### BID ####\n",
    "        if bidRate0 == prev_row.bidRate0:\n",
    "            if bidSize0 > prev_row.bidSize0:\n",
    "                bid_trd[i] = bid_trd[i-1] + 1\n",
    "            elif bidSize0 < prev_row.bidSize0:\n",
    "                bid_trd[i] = bid_trd[i-1] - 1\n",
    "            else:\n",
    "                bid_trd[i] = bid_trd[i-1]\n",
    "        else:\n",
    "            bid_trd[i] = 1\n",
    "\n",
    "        #### ASK ####\n",
    "        if askRate0 == prev_row.askRate0:\n",
    "            if askSize0 > prev_row.askSize0:\n",
    "                ask_trd[i] = ask_trd[i-1] + 1\n",
    "            elif askSize0 < prev_row.askSize0:\n",
    "                ask_trd[i] = ask_trd[i-1] - 1\n",
    "            else:\n",
    "                ask_trd[i] = ask_trd[i-1]\n",
    "        else:\n",
    "            ask_trd[i] = 1\n",
    "\n",
    "        prev_row = row\n",
    "        i += 1\n",
    "\n",
    "    df['bid_trd'] = bid_trd\n",
    "    df['ask_trd'] = ask_trd\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def signal_liquidity_to_depth(df, q):\n",
    "    def customAsk(row):\n",
    "        sizes = row[15:30].values\n",
    "        rates = row[0:15].values\n",
    "        sizes_cumsum = np.cumsum(sizes)\n",
    "        indices = sizes_cumsum <= q\n",
    "        last_index = np.sum(indices)\n",
    "        if last_index == 0:\n",
    "            q_last = q\n",
    "        else:\n",
    "            q_last = q - sizes_cumsum[max(last_index - 1, 0)]\n",
    "        res = np.dot(sizes[indices], rates[indices])\n",
    "        if last_index < 15:\n",
    "            res += q_last * rates[min(14, last_index)]\n",
    "        res /= q\n",
    "\n",
    "        return res\n",
    "\n",
    "    def customBid(row):\n",
    "        sizes = row[45:60].values\n",
    "        rates = row[30:45].values\n",
    "        sizes_cumsum = np.cumsum(sizes)\n",
    "        indices = sizes_cumsum <= q\n",
    "        last_index = np.sum(indices)\n",
    "        if last_index == 0:\n",
    "            q_last = q\n",
    "        else:\n",
    "            q_last = q - sizes_cumsum[max(last_index - 1, 0)]\n",
    "        res = np.dot(sizes[indices], rates[indices])\n",
    "        if last_index < 15:\n",
    "            res += q_last * rates[min(14, last_index)]\n",
    "        res /= q\n",
    "\n",
    "        return res\n",
    "\n",
    "    df['sigt_ask'] = df.apply(customAsk, axis=1)\n",
    "    df['sigt_bid'] = df.apply(customBid, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_ob_events(df):\n",
    "    posting_bid = np.zeros(len(df))\n",
    "    posting_bid_sizes = np.zeros(len(df))\n",
    "    posting_bid_cross = np.zeros(len(df))\n",
    "    posting_bid_cross_sizes = np.zeros(len(df))\n",
    "\n",
    "    posting_ask = np.zeros(len(df))\n",
    "    posting_ask_sizes = np.zeros(len(df))\n",
    "    posting_ask_cross = np.zeros(len(df))\n",
    "    posting_ask_cross_sizes = np.zeros(len(df))\n",
    "\n",
    "    cancellations_bid = np.zeros(len(df))\n",
    "    cancellations_bid_sizes = np.zeros(len(df))\n",
    "\n",
    "    cancellations_ask = np.zeros(len(df))\n",
    "    cancellations_ask_sizes = np.zeros(len(df))\n",
    "\n",
    "    trades_buy = np.zeros(len(df))\n",
    "    trades_buy_sizes = np.zeros(len(df))\n",
    "    trades_sell = np.zeros(len(df))\n",
    "    trades_sell_sizes = np.zeros(len(df))\n",
    "\n",
    "    i = 0\n",
    "    prev_row = df.iloc[0]\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        prev_bid_size = prev_row[45:60]\n",
    "        prev_ask_size = prev_row[15:30]\n",
    "        prev_bid_rate = prev_row[30:45]\n",
    "        prev_ask_rate = prev_row[0:15]\n",
    "\n",
    "        askRate0 = row.askRate0\n",
    "        bidRate0 = row.bidRate0\n",
    "        askSize0 = row.askSize0\n",
    "        bidSize0 = row.bidSize0\n",
    "\n",
    "        #### BID ####\n",
    "        if bidRate0 == prev_row.bidRate0:\n",
    "            # New trades added\n",
    "            if bidSize0 > prev_row.bidSize0:\n",
    "                posting_bid[i] = 1\n",
    "                posting_bid_sizes[i] = bidSize0 - prev_row.bidSize0\n",
    "            # Traded at bid\n",
    "            elif bidSize0 < prev_row.bidSize0:\n",
    "                cancellations_bid[i] = 1\n",
    "                cancellations_bid_sizes[i] = prev_row.bidSize0 - bidSize0\n",
    "\n",
    "        elif bidRate0 < prev_row.bidRate0:\n",
    "            # someone traded and consumed some orders up to new best bid\n",
    "            trades_sell[i] = 1\n",
    "            trades_sell_sizes[i] = np.sum(prev_bid_size[(prev_bid_rate >= bidRate0).values]) - bidSize0\n",
    "\n",
    "        elif bidRate0 > prev_row.bidRate0:\n",
    "            # Post but above best bid\n",
    "            posting_bid_cross[i] = 1\n",
    "            posting_bid_cross_sizes[i] = np.sum(prev_ask_size[(prev_ask_rate <= bidRate0).values]) + bidSize0\n",
    "        #############\n",
    "\n",
    "        #### ASK ####\n",
    "        if askRate0 == prev_row.askRate0:\n",
    "            # New trades added\n",
    "            if askSize0 > prev_row.askSize0:\n",
    "                posting_ask[i] = 1\n",
    "                posting_ask_sizes[i] = askSize0 - prev_row.askSize0\n",
    "            # Traded at ask\n",
    "            elif askSize0 < prev_row.askSize0:\n",
    "                cancellations_ask[i] = 1\n",
    "                cancellations_ask_sizes[i] = prev_row.askSize0 - askSize0\n",
    "\n",
    "        elif askRate0 > prev_row.askRate0:\n",
    "            # someone traded and consumed some orders up to new best ask\n",
    "            trades_buy[i] = 1\n",
    "            trades_buy_sizes[i] = np.sum(prev_ask_size[(prev_ask_rate <= askRate0).values]) - askSize0\n",
    "\n",
    "        elif askRate0 < prev_row.askRate0:\n",
    "            # Post but below best ask\n",
    "            posting_ask_cross[i] = 1\n",
    "            posting_ask_cross_sizes[i] = np.sum(prev_bid_size[(prev_bid_rate >= askRate0).values]) + askSize0\n",
    "        #############\n",
    "\n",
    "        prev_row = row\n",
    "        i += 1\n",
    "\n",
    "    df['posting_bid']             = posting_bid\n",
    "    df['posting_bid_sizes']       = posting_bid_sizes\n",
    "    df['posting_bid_cross']       = posting_bid_cross\n",
    "    df['posting_bid_cross_sizes'] = posting_bid_cross_sizes\n",
    "\n",
    "    df['posting_ask']             = posting_ask\n",
    "    df['posting_ask_sizes']       = posting_ask_sizes\n",
    "    df['posting_ask_cross']       = posting_ask_cross\n",
    "    df['posting_ask_cross_sizes'] = posting_ask_cross_sizes\n",
    "\n",
    "    df['cancellations_bid']       = cancellations_bid\n",
    "    df['cancellations_bid_sizes'] = cancellations_bid_sizes\n",
    "    df['cancellations_ask']       = cancellations_ask\n",
    "    df['cancellations_ask_sizes'] = cancellations_ask_sizes\n",
    "\n",
    "    df['trades_sell']             = trades_sell\n",
    "    df['trades_sell_sizes']       = trades_sell_sizes\n",
    "    df['trades_buy']              = trades_buy\n",
    "    df['trades_buy_sizes']        = trades_buy_sizes\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('C:\\\\Users\\\\gorokf\\\\Dropbox\\\\XTX\\\\datatraining.csv')\n",
    "\n",
    "# df['spread'] = (df.askRate0 - df.bidRate0)\n",
    "# df['mid'] = (df.askRate0 + df.bidRate0) * 0.5\n",
    "# df['mid_mic'] = (df.bidRate0 * df.askSize0 + df.askRate0 * df.bidSize0) / (df.bidSize0 + df.askSize0)\n",
    "# df['mid_wgt'] = (df.bidRate0 * df.bidSize0 + df.askRate0 * df.askSize0) / (df.bidSize0 + df.askSize0)\n",
    "\n",
    "# df['y_rec'] = df.mid.diff(87).shift(-87).fillna(0)\n",
    "# df['vol_y'] = df.mid.diff(87).shift(-87).fillna(0).ewm(span=500).std().fillna(0) #.shift(87).fillna(0)\n",
    "\n",
    "# df['bidSizeTotal'] = df[['bidSize0', 'bidSize1', 'bidSize2', 'bidSize3', 'bidSize4', 'bidSize5', 'bidSize6', 'bidSize7', 'bidSize8', 'bidSize9']].sum(axis=1)\n",
    "# df['askSizeTotal'] = df[['askSize0', 'askSize1', 'askSize2', 'askSize3', 'askSize4', 'askSize5', 'askSize6', 'askSize7', 'askSize8', 'askSize9']].sum(axis=1)\n",
    "\n",
    "# df[[col for col in df.columns if 'Size' in col]] = df[[col for col in df.columns if 'Size' in col]].fillna(0)\n",
    "\n",
    "# df = add_nbr_trades(df)\n",
    "\n",
    "# df['sig1'] = (df.bidSize0 - df.askSize0) / (df.bidSize0 + df.askSize0)\n",
    "# df['sig2'] = (df.bidSize1 - df.askSize1) / (df.bidSize1 + df.askSize1)\n",
    "# df['sig3'] = z_score(df.bidSize0 + df.bidSize1 + df.bidSize2, 50) - z_score(df.askSize0 + df.askSize1 + df.askSize2, 50)\n",
    "# df['sig4'] = df.bidSize1 / df.bidSize0 - df.askSize1 / df.askSize0 # Maybe drop it eventually\n",
    "# df['sig5'] = z_score(df.bidSize0, 50) - z_score(df.askSize0, 50)\n",
    "# df['sig6'] = z_score(df.bidSizeTotal, 20) - z_score(df.askSizeTotal, 20)\n",
    "# df['sig7'] = ((df.askRate1 - df.askRate0) - (df.bidRate0 - df.bidRate1)).fillna(0)\n",
    "# df['sig8'] = (((df.bidRate1 - df.bidRate2) - (df.askRate2 - df.askRate1)) / ((df.bidRate1 - df.bidRate2) + (df.askRate2 - df.askRate1))).fillna(0)\n",
    "# df['sig9'] = z_score(df.mid_mic, 10)\n",
    "# df['sig10'] = z_score(df.bidRate0, 20) + z_score(df.askRate0, 20)\n",
    "# df['sig11'] = z_score(df.bid_trd, 10) - z_score(df.ask_trd, 10)\n",
    "\n",
    "df = pd.read_csv('C:\\\\Users\\\\gorokf\\\\Dropbox\\\\XTX\\\\datatraining2.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "dfs = pd.read_csv('C:\\\\Users\\\\gorokf\\\\Dropbox\\\\XTX\\\\gorokf\\\\data.csv')\n",
    "\n",
    "# df = signal_liquidity_to_depth(df, 20)\n",
    "# df['sig12'] = ((df.mid - df.sigt_bid) - (df.sigt_ask - df.mid)) / ((df.mid - df.sigt_bid) + (df.sigt_ask - df.mid))\n",
    "\n",
    "# df = fill_ob_events(df)\n",
    "\n",
    "df['sig13'] = ((df.posting_bid_sizes + df.posting_bid_cross_sizes - df.cancellations_bid_sizes - df.trades_sell_sizes).ewm(span=10, adjust=False).mean() - (df.posting_ask_sizes + df.posting_ask_cross_sizes - df.cancellations_ask_sizes - df.trades_buy_sizes).ewm(span=10, adjust=False).mean()).clip(-4, 4)\n",
    "df['sig14'] = (df.posting_bid + df.posting_bid_cross - df.cancellations_bid - df.trades_sell).ewm(span=10, adjust=False).mean() - (df.posting_ask + df.posting_ask_cross - df.cancellations_ask - df.trades_buy).ewm(span=10, adjust=False).mean()\n",
    "df['sig15'] = (df.cancellations_bid_sizes.ewm(span=10, adjust=False).mean() - df.cancellations_ask_sizes.ewm(span=10, adjust=False).mean()).clip(-4., 4.)\n",
    "df['sig16'] = (df.posting_bid_cross).ewm(span=10).mean() - (df.posting_ask_cross).ewm(span=10).mean()\n",
    "\n",
    "signals = ['sig1', 'sig2', 'sig3', 'sig4', 'sig5', 'sig6', 'sig7', 'sig8', 'sig11', 'sig13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(df.y.value_counts())\n",
    "df.y.hist(bins=df.y.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(df.index, df.mid, color='r')\n",
    "# ax2.plot(df.index, df.vol, color='b')\n",
    "\n",
    "ax1.set_xlabel('Timestamp')\n",
    "ax1.set_ylabel('mid', color='r')\n",
    "# ax2.set_ylabel('y', color='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.acorr(df.sig1[0:1000000], maxlags=200)\n",
    "plt.title('Autocorrelation of y')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "askSizes = df.iloc[0][[col for col in df.columns if 'askSize' in col and 'Total' not in col]].cumsum()\n",
    "bidSizes = df.iloc[0][[col for col in df.columns if 'bidSize' in col and 'Total' not in col]].cumsum()\n",
    "\n",
    "askRates = df.iloc[0][[col for col in df.columns if 'askRate' in col]]\n",
    "bidRates = df.iloc[0][[col for col in df.columns if 'bidRate' in col]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "line1, = ax.step(bidRates[::-1], bidSizes[::-1], 'r')\n",
    "line2, = ax.step(askRates, askSizes, 'b')\n",
    "fig.legend(['bids', 'asks'])\n",
    "\n",
    "def update(index = 0):\n",
    "\n",
    "    dft = df.iloc[index]\n",
    "    askSizes = dft[[col for col in df.columns if 'askSize' in col and 'Total' not in col]].cumsum()\n",
    "    bidSizes = dft[[col for col in df.columns if 'bidSize' in col and 'Total' not in col]].cumsum()\n",
    "\n",
    "    askRates = dft[[col for col in df.columns if 'askRate' in col]]\n",
    "    bidRates = dft[[col for col in df.columns if 'bidRate' in col]]\n",
    "    \n",
    "    line1.set_xdata(bidRates[::-1])\n",
    "    line1.set_ydata(bidSizes[::-1])\n",
    "    \n",
    "    line2.set_xdata(askRates)\n",
    "    line2.set_ydata(askSizes)\n",
    "    \n",
    "    plt.xlim(bidRates[::-1].min() - 1, askRates.max() + 1)\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "\n",
    "pyw.interact(update, index=pyw.widgets.IntSlider(min=df.index[0], max=df.index[-1], step=1, value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df1 = df\n",
    "df1['y_rec'] = df1.mid.diff(87).shift(-87)\n",
    "df1['y_rec'].clip_lower(-5., inplace=True)\n",
    "df1['y_rec'].clip_upper(5., inplace=True)\n",
    "df1['diff'] = df1.y_rec - df1.y\n",
    "df1['diff'].dropna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from tree.ModelTree import ModelTree\n",
    "from tree.utils import load_csv_data, cross_validate\n",
    "from tree.mean_regr import mean_regr\n",
    "from tree.linear_regr import linear_regr\n",
    "\n",
    "model_tree = ModelTree(linear_regr(), max_depth=1, min_samples_leaf=1000, search_type='greedy', n_search_grid=10)\n",
    "\n",
    "signals = ['sig1', 'vol_y']\n",
    "X = df[0:100000][signals].values\n",
    "y = df[0:100000].y.values\n",
    "\n",
    "model_tree.fit(X, y, verbose=True)\n",
    "y_pred = model_tree.predict(X)\n",
    "explanations = model_tree.explain(X, signals)\n",
    "loss = model_tree.loss(X, y, y_pred)\n",
    "model_tree.export_graphviz(os.path.join(\"output\", \"model_tree\"), signals, export_png=True, export_pdf=False)\n",
    "print(r2_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def online_learning(df, signals, idx_init, idx_end, window, alpha):\n",
    "\n",
    "    dft = df[['y'] + signals]\n",
    "    dft_init = dft[0:idx_init]\n",
    "    dft_test = dft[idx_init:idx_end]\n",
    "\n",
    "    model = LinearRegression(fit_intercept=False, normalize=False)\n",
    "    model.fit(dft_init[signals], dft_init.y)\n",
    "\n",
    "    theta = np.zeros((idx_end, len(signals)))\n",
    "    theta[0:idx_init, :] = model.coef_\n",
    "    y_hat = np.zeros(idx_end)\n",
    "    y = np.zeros(idx_end)\n",
    "    x = np.zeros((idx_end, len(signals)))\n",
    "\n",
    "    lag = 88\n",
    "    index = idx_init\n",
    "    for _, row in dft_test.iterrows():\n",
    "        x_it = np.array([row.sig1, row.sig2, row.sig3])\n",
    "        theta_prev = theta[index - 1, :]\n",
    "        \n",
    "        theta[index, :] = theta_prev - alpha * (y_hat[index - lag] - y[index - lag]) * x[index - lag]\n",
    "        y_hat[index] = np.clip(np.dot(x_it, theta_prev), -5, 5)\n",
    "        y[index] = row.y\n",
    "        x[index, :] = x_it\n",
    "\n",
    "        index += 1\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1)    \n",
    "    ax.plot(theta)\n",
    "    ax.legend(signals)\n",
    "    plt.title('Time Series of online regression coefficients, alpha=%.5f' % alpha)\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    dft_test['y_hat'] = y_hat[idx_init:idx_end]\n",
    "    dft_test['error_pred'] = (dft_test.y - dft_test.y_hat)**2\n",
    "    dft_test['error_mean'] = (dft_test.y - dft_test.y.rolling(window).mean())**2\n",
    "    dft_test['r2'] = 1 - dft_test.error_pred.rolling(window).sum() / dft_test.error_mean.rolling(window).sum()\n",
    "    dft_test['r2'] = dft_test.r2.clip(upper=1, lower=-1)\n",
    "    ax.plot(dft_test.r2)\n",
    "    plt.title('R2 Rolling(window=%.0f), R2 Global:%.5f' % (window, r2_score(dft_test.y, dft_test.y_hat)))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "alpha = 0.00002\n",
    "idx_init = 100000\n",
    "idx_end = len(df)\n",
    "window = 100000\n",
    "signals = ['sig1', 'sig2', 'sig3']\n",
    "\n",
    "online_learning(df, signals, idx_init, idx_end, window, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def loop_regression(df, lag):\n",
    "\n",
    "    y = df.y\n",
    "    x = df.sig1\n",
    "    \n",
    "    na = x.isna() | y.isna() | np.isinf(w) | w.isna()\n",
    "    y = y[~na]\n",
    "    x = x[~na]\n",
    "    w = w[~na]\n",
    "    \n",
    "    model = LinearRegression(fit_intercept=False).fit(x[:, np.newaxis], y, w)\n",
    "    y_pred = model.predict(x[:, np.newaxis])\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    coef = model.coef_\n",
    "    return r2#, coef\n",
    "\n",
    "r = range(5, 500, 20)\n",
    "results = [loop_regression(df, lag) for lag in r]\n",
    "plt.plot(r, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "a = 2. / (N + 1.)\n",
    "bias = (2. - a) / 2. / (1. - a)\n",
    "adjust = False\n",
    "mean = df.mid_mic.ewm(span=N, adjust=adjust).mean()\n",
    "mean_calc = (1. - a) * mean.shift(1) + a * df.mid_mic\n",
    "df['error'] = mean - mean_calc\n",
    "df.error.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano\n",
    "\n",
    "x = df[0:100000].sig1\n",
    "y = df[0:100000].y\n",
    "\n",
    "with pm.Model() as model:\n",
    "    std = pm.Uniform(\"std\", 0., 1.)\n",
    "    beta = pm.Normal(\"beta\", mu=0.0, sd=10)\n",
    "    mean = pm.Deterministic(\"mean\", beta*x)\n",
    "    obs = pm.Normal(\"obs\", mu=mean, sd=std, observed=y)\n",
    "    trace = pm.sample(50000, step=pm.Metropolis())\n",
    "    \n",
    "# pm.plots.traceplot(trace, varnames=['std', 'beta'])\n",
    "# pm.plot_posterior(trace, varnames=[\"std\", \"beta\"], kde_plot=True)\n",
    "\n",
    "def stock_loss(price, pred, coef = 500):\n",
    "    sol = np.zeros_like(price)\n",
    "    ix = price*pred < 0 \n",
    "    sol[ix] = coef*pred**2 - np.sign(price[ix])*pred + abs(price[ix])\n",
    "    sol[~ix] = abs(price[~ix] - pred)\n",
    "    return sol\n",
    "\n",
    "std_samples = trace[\"std\"]\n",
    "beta_samples = trace[\"beta\"]\n",
    "N = std_samples.shape[0]\n",
    "noise = std_samples*np.random.randn(N) \n",
    "\n",
    "possible_outcomes = lambda signal: beta_samples*signal + noise\n",
    "\n",
    "opt_predictions = np.zeros(200)\n",
    "trading_signals =  np.linspace(x.min(), x.max(), 200)\n",
    "for i, _signal in enumerate(trading_signals):\n",
    "        _possible_outcomes = possible_outcomes(_signal)\n",
    "        tomin = lambda pred: stock_loss(_possible_outcomes, pred).mean()\n",
    "        opt_predictions[i] = scipy.optimize.fmin(tomin, 0, disp = False)\n",
    "        \n",
    "plt.xlabel(\"trading signal\")\n",
    "plt.ylabel(\"prediction\")\n",
    "plt.title(\"Least-squares prediction vs. Bayes action prediction\")\n",
    "plt.xlim(x.min(), x.max())\n",
    "plt.plot(trading_signals, opt_predictions, label =\"Bayes action prediction\")\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "a = 2. / (N + 1.)\n",
    "bias = (2. - a) / 2. / (1. - a)\n",
    "adjust = False\n",
    "mean = df.mid_mic.ewm(span=N, adjust=adjust).mean()\n",
    "var = df.mid_mic.ewm(span=N, adjust=adjust).var()\n",
    "vol = df.mid_mic.ewm(span=N, adjust=adjust).std()\n",
    "var_calc = (1. - a) * (var.shift(1) + bias * a * (df.mid - mean.shift(1))**2)\n",
    "df['error'] = np.sqrt(var_calc) - vol\n",
    "\n",
    "zscore_pandas = z_score(df.mid_mic, N)\n",
    "zscore_calc = (df.mid_mic - mean) / vol\n",
    "df['error'] = zscore_pandas - zscore_calc\n",
    "\n",
    "df.error.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def customAsk(row, size):\n",
    "    data = [(x >= size) for x in row[15:30]]\n",
    "    try:\n",
    "        distance = data.index(True) + 1\n",
    "    except:\n",
    "        distance = np.nan\n",
    "        \n",
    "    return sum(data), distance\n",
    "\n",
    "def customBid(row, size):\n",
    "    data = [(x >= size) for x in row[45:60]]\n",
    "    try: \n",
    "        distance = data.index(True) + 1 \n",
    "    except:\n",
    "        distance = np.nan\n",
    "        \n",
    "    return sum(data), distance\n",
    "\n",
    "df['nbrBigTradesAsk'], df['distToBigTradeAsk'] = zip(*df.apply(customAsk, args=(20,), axis=1))\n",
    "df['nbrBigTradesBid'], df['distToBigTradeBid'] = zip(*df.apply(customBid, args=(20,), axis=1))\n",
    "\n",
    "# test_double_signal(df, 'distToBigTradeAsk', 'distToBigTradeBid')\n",
    "# test_double_signal(df, 'nbrBigTradesAsk', 'nbrBigTradesBid')\n",
    "\n",
    "df['sig_test'] = z_score(df.distToBigTradeBid, 10) - z_score(df.distToBigTradeAsk, 10)\n",
    "test_signal_full(df, 'sig_test', signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class CustomModel(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for i, model in enumerate(self.models):\n",
    "            if model['continuous']:\n",
    "                models[i]['model'] = model['model'].fit(X[model['signals']], y)\n",
    "            elif len(model['signals']) == 1:\n",
    "                indices = X[model['signals'][0]] != 0\n",
    "                models[i]['model'] = model['model'].fit(X[indices][model['signals']], y[indices])\n",
    "            else:\n",
    "                raise Exception('toto')\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        n = np.zeros(len(X))\n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        for i, model in enumerate(models):\n",
    "            predictions = predictions + model['model'].predict(X[model['signals']])\n",
    "\n",
    "            if model['continuous']:\n",
    "                n = n + 1\n",
    "            elif len(model['signals']) == 1:\n",
    "                n = n + (X[model['signals'][0]] != 0)\n",
    "            else:\n",
    "                raise Exception('Error')\n",
    "        \n",
    "        return predictions / n\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return(r2_score(y, self.predict(X)))\n",
    "\n",
    "models = (\n",
    "    {\n",
    "        'model': LinearRegression(fit_intercept=False),\n",
    "        'signals': ['sig1', 'sig2', 'sig3', 'sig4', 'sig5', 'sig6'],\n",
    "        'continuous': True,\n",
    "    },\n",
    "    {\n",
    "        'model': LinearRegression(fit_intercept=False),\n",
    "        'signals': ['sig7'],\n",
    "        'continuous': False,\n",
    "    },\n",
    ")\n",
    "\n",
    "# signals = ['sig1', 'sig2', 'sig3', 'sig4', 'sig5', 'sig7']\n",
    "# X = df[signals]\n",
    "# y = df.y\n",
    "\n",
    "model = CustomModel(models)\n",
    "# model.fit(X, y)\n",
    "# y_hat = model.predict(X)\n",
    "# r2_score(y, y_hat)\n",
    "plot_regression(df, ['sig1', 'sig2', 'sig3', 'sig4', 'sig5', 'sig6', 'sig7'], model=model, plot=False)\n",
    "plot_regression(df, ['sig1', 'sig2', 'sig3', 'sig4', 'sig5', 'sig6', 'sig7'], plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=False)\n",
    "\n",
    "signals = ['sig1', 'sig2', 'sig3', 'sig4', 'sig5', 'sig6', 'sig7', 'sig8', 'sig11', 'sig13']\n",
    "x = df[signals]\n",
    "y = df.y\n",
    "selector = RFE(model, 1, step=1, verbose=True)\n",
    "selector = selector.fit(x, y)\n",
    "print(dict(zip(signals, selector.ranking_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dft = df[0:1000000]\n",
    "\n",
    "def customAsk(row):\n",
    "    x = row[15:30].values\n",
    "    return np.ptp(x), scipy.stats.mode(x).mode[0], scipy.stats.iqr(x, axis=0 , rng=(25, 75), interpolation='lower'), scipy.stats.skew(x), scipy.stats.kurtosis(x,axis=0,fisher=False)\n",
    "        \n",
    "def customBid(row):\n",
    "    x = row[45:60].values\n",
    "    return np.ptp(x), scipy.stats.mode(x).mode[0], scipy.stats.iqr(x, axis=0 , rng=(25, 75), interpolation='lower'), scipy.stats.skew(x), scipy.stats.kurtosis(x,axis=0,fisher=False)\n",
    "\n",
    "dft['ptp_ask'], dft['mode_ask'], dft['iqr_ask'], dft['skew_ask'], dft['kurt_ask'] = zip(*dft.apply(customAsk, axis=1))\n",
    "dft['ptp_bid'], dft['mode_bid'], dft['iqr_bid'], dft['skew_bid'], dft['kurt_bid'] = zip(*dft.apply(customBid, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "ecdf = ECDF(df[df.askSize0 < 20].askSize0)\n",
    "plt.plot(ecdf.x, ecdf.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=len(signals))\n",
    "pca.fit(df[signals])\n",
    "print(np.cumsum(pca.explained_variance_ratio_))\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dft = group_by_levels(df[80000:85000]).drop('y', axis=1)\n",
    "plot_order_size(dft, only_size=True)\n",
    "plot_order_size(dft, only_size=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def print_lowess(df, signals):\n",
    "    for sig in signals:\n",
    "        lowess = sm.nonparametric.lowess(df.y, df[sig], frac=.1)\n",
    "\n",
    "        lowess_x = list(zip(*lowess))[0]\n",
    "        lowess_y = list(zip(*lowess))[1]\n",
    "\n",
    "        f = interp1d(lowess_x, lowess_y, bounds_error=False)\n",
    "\n",
    "        xnew = np.linspace(-1., 1., 101)\n",
    "        ynew = f(xnew)\n",
    "\n",
    "        plt.plot(lowess_x, lowess_y, '*')\n",
    "        plt.plot(xnew, ynew, '-')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class SumModel(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for i in range(len(self.models)):\n",
    "            self.models[i].fit(X, y)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        for i in range(len(self.models)):\n",
    "            predictions = predictions + self.models[i].predict(X)\n",
    "        \n",
    "        return predictions / len(self.models)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return(r2_score(y, self.predict(X)))\n",
    "\n",
    "model1 = XGBRegressor(n_estimators=150, objective='reg:squarederror', booster='gbtree', learning_rate=0.04, gamma=0, subsample=0.4, colsample_bytree=0.5, max_depth=4, reg_lambda=1e3, nthreads=6)\n",
    "model2 = HuberRegressor(fit_intercept=False, epsilon=1.35)\n",
    "model = SumModel([model1, model2])\n",
    "plot_regression(df, signals, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "group_by_levels(df.iloc[2992300:2992400], show_trades=False, negative_ask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "display_2d_relationship(df, 'askSize0', 'bidSize0', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_train = df.iloc[:2000000, :] \n",
    "df_test = df.iloc[2000000:, :]\n",
    "\n",
    "model1 = LinearRegression(fit_intercept=False, normalize=False)\n",
    "model2 = LinearRegression(fit_intercept=False, normalize=False)\n",
    "model3 = LinearRegression(fit_intercept=False, normalize=False)\n",
    "\n",
    "model1.fit(df_train[signals], df_train.y)\n",
    "y_pred1 = model1.predict(df_test[signals])\n",
    "y_pred2 = y_pred1 * 0\n",
    "y_pred3 = y_pred1 * 0\n",
    "\n",
    "turns = 50000\n",
    "\n",
    "i = 0\n",
    "for _, row in df_test[signals].iterrows():\n",
    "    if (i+1) % turns == 0:\n",
    "        model2.fit(df_test[signals].iloc[0:i], df_test.iloc[0:i].y)\n",
    "        model3.fit(df_test[signals].iloc[i - turns + 1:i], df_test.iloc[i - turns + 1:i].y)\n",
    "    \n",
    "    if i > turns:\n",
    "        y_pred2[i] = model2.predict(np.array([row]))\n",
    "        y_pred3[i] = model3.predict(np.array([row]))\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "y_pred = np.where(np.array(range(len(df_test))) <= turns, y_pred1, 0.3333 * (y_pred1 + y_pred2 + y_pred3))\n",
    "\n",
    "print(r2_score(df_test.y, y_pred1))\n",
    "print(r2_score(df_test.y, y_pred2))\n",
    "print(r2_score(df_test.y, np.where(np.array(range(len(df_test))) <= turns, y_pred1, 0.5 * (y_pred1 + y_pred2))))\n",
    "print(r2_score(df_test.y, y_pred3))\n",
    "print(r2_score(df_test.y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = XGBRegressor(n_estimators=150, objective='reg:squarederror', booster='gbtree', learning_rate=0.04, gamma=0, subsample=0.4, colsample_bytree=0.5, max_depth=4, reg_lambda=1e3, nthreads=6)\n",
    "\n",
    "param_grid=params = {\n",
    "    'n_estimators': [150, 175, 200],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'learning_rate': [0.035, 0.04, 0.045],\n",
    "    'subsample': [0.3, 0.4, 0.5, 0.6],\n",
    "    'colsample_bytree': [0.4, 0.5, 0.6, 0.7],\n",
    "    'colsample_bylevel': [0.25, 0.5, 0.75],\n",
    "    'min_child_weight': [1.0, 5.0, 10.0, 15.0, 20.0],\n",
    "    'gamma': [0, 0.5, 1.0],\n",
    "    'reg_lambda': [100.0, 1e3, 1e4],\n",
    "    'max_depth': [4, 5, 6]\n",
    "}\n",
    "gs = RandomizedSearchCV(model, param_grid, n_iter=300, verbose=3, cv=TimeSeriesSplit(n_splits=2), random_state=42, refit=True) \n",
    "gs.fit(df[signals].values, df.y)\n",
    "best_score = gs.best_score_\n",
    "best_params = gs.best_params_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "explain_error_vs_signal(df, signals, df.spread.ewm(span=100, adjust=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABbkAAAP/CAYAAADtE8HyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdf5Dtd10f/ucruZtQzV6gJkHupZmYQlJIGrEslU5FSwZQRhFHHEeGAoX0UqQw1op18Fu+M3WwA06nQ5VJkWtRKT9CoCRji8jYKqBIiXtJzA8rlfj9WpMlhOAk9wrmckne/eOevdlczt492d2zn8979/GY2dnd1/mcz+f1eZ2z5+x5ns9+tlprAQAAAACAHp01dAMAAAAAALBZQm4AAAAAALol5AYAAAAAoFtCbgAAAAAAuiXkBgAAAACgW/uGbmBI559/frv44ouHbgMAAAAAgDM4cuTIva21C6ZdtqdD7osvvjjLy8tDtwEAAAAAwBlU1Z+vd5nTlQAAAAAA0C0hNwAAAAAA3RJyAwAAAADQLSE3AAAAAADdEnIDAAAAANAtITcAAAAAAN0ScgMAAAAA0C0hNwAAAAAA3RJyAwAAAADQLSE3AAAAAADdEnIDAAAAANAtITcAAAAAAN0ScgMAAAAA0C0hNwAAAAAA3RJyAwAAAADQLSE3AAAAAADdEnIDAAAAANAtITcAAAAAAN0ScgMAAAAA0C0hNwAAAAAA3RJyAwAAAADQLSE3AAAAAADdEnIDAAAAANAtITcAAAAAAN0ScgMAAAAA0C0hNwAAAAAA3RJyAwAAAADQLSE3AAAAAADdEnIDAAAAANAtITcAAAAAAN0ScgMAAAAA0C0hNwAAAAAA3RJyAwAAAADQLSE3AAAAAADdEnIDAAAAANAtITcAAAAAAN0ScgMAAAAA0C0hNwAAAAAA3RJyAwAAAADQLSE3AAAAAADdEnIDAAAAANAtITcAAAAAAN3aN3QDAADztv9wcuzE0F1sj8WF5OihR3+93TQDdq/N3r8fLT8PsHft1OMMwKO13u8nHrdm40huAGDX201h1mb3ZTfNgN1rp+6nfh5g7/LzD4zVeo9PHrdmI+QGAAAAAKBbQm4AYNdbXBi6g+2z2X3ZTTNg99qp+6mfB9i7/PwDY7Xe45PHrdlUa23oHgaztLTUlpeXh24DAAAAAIAzqKojrbWlaZc5khsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbu0bugEY2v7Dj/z+6KGHa0cP7ez29lptq+sZk+2e0Zhs1+3V031rL9RmuXwIY7oNx9BDj7Ux9DD22hh6GHttDD2MvTaGHnqsjaGHsdfG0MPYa2PoYey1MfTQY22r69ltps1lDLfTTteYjSO5AQAAAADoVrXWhu5hMEtLS215eXnoNgAAAAAAOIOqOtJaW5p2mSO5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBu7Ru6AcZj/+Hk2ImhuwCA7be4kBw9NHQXAAAAzIMjuTlFwA3AbuU5DgAAYPcScgMAAAAA0C0hN6csLgzdAQDMh+c4AACA3cs5uTnFuUoBAAAAgN44khsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOjW3ELuqnpXVd1TVbedVn99VX2uqm6vql+Y1J5XVUeq6tbJ56sm9cWqunnNx71V9bYp27q4qv56zXLvmNd+AQAAAAAwHvvmuO5fS/L2JO9eLVTVc5K8KMmVrbXjVXXh5KJ7k7ywtbZSVVck+ViSg621Y0mevub6R5J8eJ3t3dFae/o6lwEAAAAAsAvNLeRurX2yqi4+rfzjSd7SWjs+Weaeyeeb1ixze5LHVNW5q8slSVU9JcmFSX5vXj0DAAAAANCXnT4n96VJnl1Vn6mqT1TVM6cs8+IkN60NuCdekuQDrbW2zrq/rapumqz32dvZNAAAAAAA4zTP05Wst73HJ3lWkmcmua6qLlkNrqvq8iRvTfL8Kdf9sSQvW2e9X0hyUWvty1X1jCQ3VNXlrbWjpy9YVa9O8uokueiii7a6PwAAAAAADGinj+S+M8mH20k3JnkoyflJUlVPSnJ9kpe31u5Ye6Wq+vYk+1prR6attLV2vLX25cnXR5LckZNHjU9b9p2ttaXW2tIFF1ywXfsFAAAAAMAAdjrkviHJVUlSVZcmOSfJvVX1uCQfSfLG1tqnplzvJUnev95Kq+qCqjp78vUlSZ6S5M+2uXcAAAAAAEZmbiF3Vb0/yaeTXFZVd1bV1UneleSSqrotybVJXjE5Vcnrkjw5yZuq6ubJx4VrVvejOS3krqofrKqfm3z73Uluqao/SvKhJK9prf3lvPYNAAAAAIBxqPX/j+Put7S01JaXl4duAwAAAACAM6iqI621pWmX7fTpSgAAAAAAYNsIuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOjWvqEbYDz2H06OnRi6CwCYr8WF5OihobsAAABguwi5OUXADcBecOzEyTd2jx46+XmttbWNLlebXhtDD2OvjaGHsdfG0MPYa2PoocfaGHoYe20MPYy9NoYexl4bQw891sbQw9hrY+hhp2vMxulKAAAAAADoVrXWhu5hMEtLS215eXnoNkZj/2FHcwOw+zldCQAAQH+q6khrbWnaZU5Xwile8AMAAAAAvXG6EgAAAAAAuiXkBgAAAACgW0JuAAAAAAC6JeQGAAAAAKBbQm4AAAAAALol5AYAAAAAoFtCbgAAAAAAuiXkBgAAAACgW0JuAAAAAAC6JeQGAAAAAKBbQm4AAAAAALol5AYAAAAAoFtCbgAAAAAAuiXkBgAAAACgW0JuAAAAAAC6JeQGAAAAAKBbQm4AAAAAALol5AYAAAAAoFtCbgAAAAAAuiXkBgAAAACgW0JuAAAAAAC6JeQGAAAAAKBbQm4AAAAAALol5AYAAAAAoFtCbgAAAAAAuiXkBgAAAACgW0JuAAAAAAC6JeQGAAAAAKBbQm4AAAAAALol5AYAAAAAoFtCbgAAAAAAuiXkBgAAAACgW0JuAAAAAAC6JeQGAAAAAKBbQm4AAAAAALol5AYAAAAAoFtCbgAAAAAAuiXkBgAAAACgW0JuAAAAAAC6JeQGAAAAAKBbQm4AAAAAALol5AYAAAAAoFtCbgAAAAAAurVv6AYYj/2Hk2Mnhu4CAHbO4kJy9NDQXQAAALAVQm5OEXADsNccO5HUNUN3AQAA8I0clDM7pysBAAAAABgZB6TOTsgNAAAAAEC3hNwAAAAAACOzuDB0B/1wTm5OWVzwZxAA7C3OcQcAANA/ITeneJEPAAAAAPTG6UoAAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbu0bugGGtf9wcuzE0F0AAAAAAOtZXEiOHhq6i/FyJPceJ+AGAAAAgHGT4Z3Z3ELuqnpXVd1TVbedVn99VX2uqm6vql+Y1J5XVUeq6tbJ56vWLP/xyfI3Tz4uXGd7b6yqz0+W/d557RcAAAAAAOMxz9OV/FqStyd592qhqp6T5EVJrmytHV8TWN+b5IWttZWquiLJx5IcXLOul7bWltfbUFU9LcmPJbk8yYEk/72qLm2tPbidOwQAAAAAwLjM7Uju1tonk/zlaeUfT/KW1trxyTL3TD7f1FpbmSxze5LHVNW5j2JzL0pybWvteGvt/0vy+SR/f0s7AAAAAADA6O30ObkvTfLsqvpMVX2iqp45ZZkXJ7lpNQif+NXJqUreVFU15ToHk/zFmu/vzCOPBD+lql5dVctVtfylL31ps/sBAAAAAMAI7HTIvS/J45M8K8lPJ7lubWhdVZcneWuSf7bmOi9trf3dJM+efLxsynqnBd9tWgOttXe21pZaa0sXXHDB5vYCAAAAAIBR2OmQ+84kH24n3ZjkoSTnJ0lVPSnJ9Ule3lq7Y/UKrbW7Jp+PJXlfpp+G5M4kf2vN909KsjJlOQAAAAAAdpGdDrlvSHJVklTVpUnOSXJvVT0uyUeSvLG19qnVhatqX1WthuALSX4gyW1T1vsbSX6sqs6tqm9L8pQkN851TwAAAAAAGNzcQu6qen+STye5rKrurKqrk7wrySVVdVuSa5O8orXWkrwuyZOTvGly7u2bq+rCJOcm+VhV3ZLk5iR3JTk8Wf8PVtXPJUlr7fYk1yX54yS/leSft9YenNe+7SaLC0N3AAAAAACciQzvzOpkxrw3LS0tteXl5aHbAAAAAADgDKrqSGttadplO326EgAAAAAA2DZCbgAAAAAAuiXkBgAAAACgW0JuAAAAAAC6JeQGAAAAAKBbQm4AAAAAALol5AYAAAAAoFtCbgAAAAAAuiXkBgAAAACgW0JuAAAAAAC6JeQGAAAAAKBbQm4AAAAAALol5AYAAAAAoFtCbgAAAAAAuiXkBgAAAACgW0JuAAAAAAC6JeQGAAAAAKBb+4ZugHHZfzg5duLh7xcXTn4+duKRX0+7XG0cPfRYG0MPY6+NoYex18bQQ4+1MfQw9toYehh7bQw9jL02hh56rI2hh7HXxtDD2Gtj6GHstTH00GNtDD2MvTaGHsZeG0MPY6+NoYehaosLydFDYQbVWhu6h8EsLS215eXlodsYlbpm6A4AAAAAgCRprx26g/GoqiOttaVplzldCY+w+m7R2u9Xa2u/nna52jh66LE2hh7GXhtDD2OvjaGHHmtj6GHstTH0MPbaGHoYe20MPfRYG0MPY6+NoYex18bQw9hrY+ihx9oYehh7bQw9jL02hh7GXhtDD0PVTr+M9TldCY/gTyAAAAAAgJ44khsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG7tG7oBxmP/4eTYiaG7AIBhLS4kRw8N3QUAAACzEnJzioAbAE4+H9Y1Q3cBAADgIJxZOV0JAAAAAMAIOSh1NkJuAAAAAAC6JeQGAAAAAKBbQm5OWVwYugMAAAAAYJW8bjb+8SSnOIk9AAAAANAbR3IDAAAAANAtITcAAAAAAN0ScgMAAAAA0C0hNwAAAAAA3RJyAwAAAADQLSE3AAAAAADdEnIDAAAAANAtITcAAAAAAN0ScgMAAAAA0C0hNwAAAAAA3RJyAwAAAADQLSE3AAAAAADdEnIDAAAAANAtITcAAAAAAN0ScgMAAAAA0C0hNwAAAAAA3RJyAwAAAADQLSE3AAAAAADdEnIDAAAAANCtfUM3wLjsP5wcO7Ez21pcOPl57fbGVBsD89jYmGY01llud1+7cUZbsVf2c5q98jM0lK3MY6/Mdy/fB3ficbx3Y3ruH+t8xzSPnua2FXtlP7dir8xoTD9XY53vmOaxG+e23dfdK3Z6RosLydFD27/e3ahaa0P3MJilpaW2vLw8dBujUtcM3QEAAAAAkCTttUN3MB5VdaS1tjTtMqcrAQAAAACgW0JuHmH1Tyx2alunb29MtTEwj42NaUZjneV297UbZ7QVe2U/p9krP0ND2co89sp89/J9cCcex3s3puf+sc53TPPoaW5bsVf2cyv2yozG9HM11vmOaR67cW7bfd29YqdnZPazc05uHsF5fgAAAACAnjiSGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbu0bugHGY//h5NiJobsAgHFYXEiOHhq6CwAAADYi5OYUATcAPOzYiaSu2do6FhceXtdQtdWvVz2a2lDGMLdHW9toP8bU61Dz2C7r3X+3402p1YM+eprRmG73nua2FWOahxnt3Iy28ny6XbWjh04+Tq01S22IXoeqmZG5zas25IwceDMbITcAwJxMe0G907WtrGcoY5jbo61Ns123Q4+1eVqvh9UXlJt9Ebp23T3NaEy3e09z24oxzcOMNlfbjLH0v9PX67FmRpurmdvGtbHMiOmE3AAAczKGo9Ycye1I7iFq8zTL/Xcr696p22u7jOl272luWzGmeZjRzs1oDEeSTutjltpQvZpRXzVz27g2hhmxvmqtDd3DYJaWltry8vLQbYyGc3IDwMMWF/xpIAAAwFhU1ZHW2tK0yxzJzSleyAMAAAAAvTlr6AYAAAAAAGCzhNwAAAAAAHRLyA0AAAAAQLeE3AAAAAAAdEvIDQAAAABAt4TcAAAAAAB0S8gNAAAAAEC3hNwAAAAAAHRLyA0AAAAAQLeE3AAAAAAAdEvIDQAAAABAt4TcAAAAAAB0S8gNAAAAAEC3hNwAAAAAAHRLyA0AAAAAQLeE3AAAAAAAdEvIDQAAAABAt4TcAAAAAAB0a24hd1W9q6ruqarbTqu/vqo+V1W3V9UvTGrPq6ojVXXr5PNVk/o3VdVHqupPJsu/ZZ1tXVxVf11VN08+3jGv/QIAAAAAYDz2zXHdv5bk7UnevVqoquckeVGSK1trx6vqwslF9yZ5YWttpaquSPKxJAcnl/271trvVtU5Sf5HVb2gtfbRKdu7o7X29HntDAAAAAAA4zO3kLu19smquvi08o8neUtr7fhkmXsmn29as8ztSR5TVee21r6a5Hcny3ytqj6b5Enz6plk/+Hk2Imhu9jY4sLJz2t7nVbby8xoY2a0Oea2MTPamBltzIw2x9w2ZkYb28szmnXf9/KMtsLcNmZGGzOjjZnR5pjbxnZ6RosLydFD27/e3WieR3JPc2mSZ1fVzyd5IMkbWmt/eNoyL05y02oQvqqqHpfkhUn+wzrr/raquinJ0ST/urX2e9MWqqpXJ3l1klx00UWb3pHdqpcHrWl99tL7TjGjjZnR5pjbxsxoY2a0MTPaHHPbmBltbC/PaNZ938sz2gpz25gZbcyMNmZGm2NuG9vpGZn/7HY65N6X5PFJnpXkmUmuq6pLWmstSarq8iRvTfL8tVeqqn1J3p/kF1trfzZlvV9IclFr7ctV9YwkN1TV5a21o6cv2Fp7Z5J3JsnS0lLbvl3bHRYX+vgB8u7ixsxoY2a0Oea2MTPamBltzIw2x9w2ZkYb28szciT3fJnbxsxoY2a0MTPaHHPb2BBHcjObnQ6570zy4UmofWNVPZTk/CRfqqonJbk+yctba3ecdr13JvnT1trbpq10ctT36ilQjlTVHTl51PjynPZj1/InEAAAAABAT87a4e3dkOSqJKmqS5Ock+TeyalIPpLkja21T629QlW9Ocljk/yL9VZaVRdU1dmTry9J8pQk0474BgAAAABgF5lbyF1V70/y6SSXVdWdVXV1kncluaSqbktybZJXTI7qfl2SJyd5U1XdPPm4cHJ09/+T5GlJPjup/9PJ+n+wqn5usrnvTnJLVf1Rkg8leU1r7S/ntW8AAAAAAIxDTU6HvSctLS215WVnNAEAAAAAGLOqOtJaW5p22U6frgQAAAAAALaNkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBuCbkBAAAAAOiWkBsAAAAAgG4JuQEAAAAA6JaQGwAAAACAbgm5AQAAAADolpAbAAAAAIBu7Ru6AYaz/3By7MTQXQAAAAAAs1hcSI4eGrqL8XEk9x4m4AYAAACAfsjzphNyAwAAAADQLSE3AAAAAADdEnIDAAAAANAtITcAAAAAAN0ScgMAAAAA0C0hNwAAAAAA3RJyAwAAAADQLSE3AAAAAADdEnIDAAAAANAtITcAAAAAAN0ScgMAAAAAdGBxYegOxmnf0A0wnMWF5NiJobsAgP4sLiRHDw3dBQAAAImQe0/z4hwAAAAA6J3TlQAAAAAA0C0hNwAAAAAA3RJyAwAAAADQLSE3AAAAAADdEnIDAAAAANAtITcAAAAAAN0ScgMAAAAA0C0hNwAAAAAA3RJyAwAAAADQLSE3AAAAAADdEnIDAAAAANAtITcAAAAAAN0ScgMAAAAA0C0hNwAAAAAA3do3dAOMx/7DybETQ3cBAAAAACTJ4kJy9NDQXYyfI7k5RcANAAAAAOMhr5uNkBsAAAAAgG4JuQEAAAAA6JaQm1MWF4buAAAAAABYJa+bjX88ySlOYg8AAAAA9MaR3AAAAAAAdEvIDQAAAABAt4TcAAAAAAB0S8gNAAAAAEC3hNwAAAAAAHRLyA0AAAAAQLeE3AAAAAAAdEvIDQAAAABAt4TcAAAAAAB0S8gNAAAAAEC3hNwAAAAAAHRLyA0AAAAAQLeE3AAAAAAAdEvIDQAAAABAt4TcAAAAAAB0S8gNAAAAAEC3hNwAAAAAAHRLyA0AAAAAQLeE3AAAAAAAdGvf0A0wHvsPJ8dODN0FAPRvcSE5eshzK8CjsfrYuZtt9LywF2YwD/Ocq+fyzc1vO+Y2z5+Htf3txO9t0/bFfYtZeF6YXbXWhu5hMEtLS215eXnoNkajrhm6AwAAgJMWF05+nkcING3dO1Eba39DzaOH+QohHzbE3E5f11D3me3mvsWj0V47dAfjUVVHWmtL0y5zJDcAAACjM88AaNq6d6I2q53ub6h59DjfvWyIuZ2+rqHuM9ttTL3AbuGc3AAAAIzO4sLDR17uxLp3ojbW/oaaR4/z3ct2em5jus9stzH1wri5n8zOkdyc4s9lANgtnLsOAABg7xByc4owAAAAAADojdOVAAAAAADQLSE3AAAAAADdEnIDAAAAANAtITcAAAAAAN0ScgMAAAAA0C0hNwAAAAAA3RJyAwAAAADQLSE3AAAAAADdEnIDAAAAANAtITcAAAAAAN0ScgMAAAAA0C0hNwAAAAAA3RJyAwAAAADQLSE3AAAAAADdEnIDAAAAANCtfUM3AAAAcCb7DyfHTjz66y0uJEcPbX8/AACMi5AbAACYyWbD5qEcO5HUNbMvLxQHAOiTkBsAAPaw3oLreRKKAwD0ScgNAAB7iFB7+6wXigu/AQB2lpAbmNnqi+LFhUfWx1pb+wJ+p2tD7/usNTMa94ym1Yaex7SaGfU3t1l73cp1x7CfY6qNoQd2zunh9048Ro3hvjXvx6jtfuNg/+Fv3Ma07a5XG+OMhq5Nu43WvoaY9TY8/c240/f9TOvZ6Lqn9z9tuVlrY7gvjL02hh7GXjvT5as8Rs2nNtb7wum9euN8NtVaG7qHwSwtLbXl5eWh2xiVsYeYRw898pfRWWtj6X8navOckRfIAAAM5fTfS7f6+7Pfbbff6lzXew1xpttw7euTjW6bM63H7QrsNu21Q3cwHlV1pLW2NO0yR3IDM5v2S2sy3toY34EdW82Mxj2jabWh5zGtZkb9zW3WXrdy3THs55hqY+iB4ezEY9QY7ls7+Ri1Hc4UlM5SG/uMhqqdbnHh0d+Gq9dZ+/2j3d4s191Nj+1jrY2hh7HXznT5Ko9R86mN9b5wpv5ZnyO5HckNAMAe4pzc87e44E+LAQC225aP5K6qZ7TWjpxWe2Fr7b9uR4MAAMDOWA1fhd3bR6gNADCsWU9XcriqXtFauzVJquolSf5FEiE3AAB06PRQVuh9ZoJsAIDxmjXk/pEkH6qqlyb5riQvT/L8uXUFAADsqEcb4PYaigurAQB2n5lC7tban1XVjyW5IclfJHl+a+2v59oZAAAwWoJiAADG4owhd1XdmmTtf6b8m0nOTvKZqkpr7cp5NgcAAAAAAGey0ZHcP7AjXQAAAAAAwCacMeRurf356tdV9e1Jnj359vdaa380z8YAAAAAAGAjZ82yUFX9RJL3Jrlw8vGeqnr9PBsDAAAAAICNzPSPJ5NcneQ7W6f5Ip8AACAASURBVGtfSZKqemuSTyf5pXk1BgAAAAAAG5npSO4kleTBNd8/OKkBAAAAAMBgZj2S+1eTfKaqrs/JcPtFSf7T3LoCAAAAAIAZzBRyt9b+fVV9PMl3TUqvbK3dNLeuAAAAAABgBrMeyZ2cPEVJm3w8NJ92AAAAAABgdjOdk7uqfiLJe5Ocn+TCJO+pqtfPszEAAAAAANjIrEdyX53kO1trX0mSqnprkk8n+aV5NQYAAAAAABuZ6UjunPxnkw+u+f7BSQ0AAAAAAAYz65Hcv5rkM1V1fU6G2y9K8p/m1hUAAAAAAMxgppC7tfbvq+rjSb5rUnpla+2muXUFAAAAAAAzmPV0JasqSYtTlQAAAAAAMAIzhdxV9f8m+fUkj09yfpJfrap/PcP13lVV91TVbafVX19Vn6uq26vqFya151XVkaq6dfL5qjXLP2NS/3xV/WJVfUPIXif94mSZW6rq782ybwAAAAAA9GvWc3K/JMl3tNYeSJKqekuSzyZ58wbX+7Ukb0/y7tVCVT0nJ8/pfWVr7XhVXTi56N4kL2ytrVTVFUk+luTg5LL/mOTVSf5nkt9M8n1JPnratl6Q5CmTj++cXOc7Z9w/kuw/nBw7MXQXO29xITl66Bvr85jHetvi0RnjfXW7btvdvG/0Y8j7ofsbsBmbedzyeAMA61v73Lr6nDnP2irPz2xWtdY2Xqjqo0le0lq7b/L945K8p7X2AzNc9+Ik/621dsXk++uSvLO19t/PcJ3KydD7QJK/meR3W2t/Z3LZS5L8o9baPzvtOr+c5OOttfdPvv/cZLkvrLedpaWltry8vNEu7Bl1zdAdDOD/fDb5z/8kly1+7RHlb/mWb8kfvPhjyWPO297t/c7bctlt79jede4xj3nMY/JHP/De5MDlQ7fysD//w+Q9r8pli1tPBT/3tEPJc39qG5raJg89lLzjhbns63cM3Qk75MUvfnH+7cGfH66Bwz+Sy/76to2X24Oe+tSn5sMf/nAe+yu16TchFj7wmlzyxY9va1+wHV71qlflzY//Vzv7BttnP5S/86k3ZZbXQ0D/fuZnfiY/8fVX5tiJkyFaMuzBJdN6GFNtDMY0j708t91oTPeZtbVv+uKtefIN/zjHjx9Pknzf931f3va2t824V3tDVR1prS1Nu+yMR3JX1S/l5Dm4jye5vap+e/L985L8/ib7uTTJs6vq55M8kOQNrbU/PG2ZFye5aXKk98Ekd6657M48fIT3WgeT/MWU5R4RclfVq3PyqPBcdNFFm9wFdo3//TvJyq35uz/yIzn77LOTJHfffXc+8YlPJP/wj5OL//72bu+mD+X+r96f7/me79ne9e4RX/va13L99dcnT/29cYXcn/sfycpt+fYf/dFMOZvSzD75yU8mN39oXCH3sS8mt/9m9j/zmbnkkkuG7oY5u/HGG3PttdcmPzVQyP3AseTm/5Jv+o7vyKWXXjpMDyP1p3/6p7nhhhty9OjRHDvx2M2tpLWc+J/vyVl/+6JceeWV29sgbMHv//7v54Mf/GCOvfJf7eyGb/2N3Hnnnfn+7//+nd0usON++7d/OzfccEOOfe8rk4wjwJvWw5hqYzCmeezlue1GY7rPrK199X99Irfcckt++Id/OAsLC7n44ou/8Qqsa6PTlawe5nwkyfVr6h/f4jYfn+RZSZ6Z5LqquqRNDqGoqsuTvDXJ8yfLT0uMph1uMdNyrbV3JnlncvJI7kfdPbvL/SvJOd+U66677lQ4+dnPfjbPeMYzTl42h+1d9b1X5b3vfe/2r3sP+PrXv55zzz03D83jttmK+1aSv/HYfOADH9jSal7xilfk3f/149vT03aZzPpnf/Zn80M/9EMDN8O8/fRP/3Te/va3J60lW3jDZtPuP/m+9E/+5E/mZS972c5vf8Te97735aUvfWlWVlayuPDYzb0AeeBY8rWv5FWvelXe8IY3bHuPsFlXX311fuu3fiuLCzv74vrsoyu54oorTr65B+xqL3jBCybPoXEkd0dH745pHnt5brvRmO4za2vn/NVKHtq3Lx/84Adz1lkz/RtF1jhjyN1a+/WqOjvJr7fW/vE2bfPOJB+ehNo3VtVDOfnPLL9UVU/KyTD95a21O9Ys/6Q1139SkmkJ151J/tYMy7GOnX5hMQr3r6Qed/ARR98ePHjyDwXO/auVHN/ObbWW3L9yav08evv27cu3fuu35kvHVjKqu+r9KznrcVu/XQ8ePJgc/cLJU4SM5QltEnK73+4NBw8ezAMPPJDzTtyXvzrn8TvfgPvbulZnsrKykqOHnrqpdfzJn6zkqW8wX8bn4MGDufvuu/O1Vz146i/rdsLT3r6SgweftmPbA4Zz8ODB3HLLLc7zC4zaP7lxJb/zxCcKuDdpw3882Vp7sKouqKpzWmtf22j5GdyQ5KokH6+qS5Ock+TeyXm+P5Lkja21T63Z/heq6lhVPSvJZ5K8PMkvTVnvbyR5XVVdm5P/cPL+M52Pm2+0F5/wv/valZz11AOPqF1wwQU5++yz81MX35Wff+32bevLX/7LnP+64zlw4MDGC7OuAwcO5Mrz7spHt/G22ap/8J/vynmXb/12PXDgQPLgiXzxR+/NhRdeuPEVdsAv//JKXpO43+4Rq7fzp597V664YudD7ve9byUvjfvbNKszWVnZ/Pv3d9111yPWBWNx4MCBPPTQQ/niF7+4o/fPlZWVPPe5z92x7QHDOXDgQO6+++58/etfz759G8YgAINYWVnxu/oWzPrWwP+f5FNV9aaq+perHxtdqaren+TTSS6rqjur6uok70pySVXdluTaJK+YHNX9uiRPTvKmqrp58rGa8vx4kl9J8vkkdyT56GT9r6mq10yW+c0kfzZZ5nCSEUVgjNVdd931DQ8gZ511Vp74xCduKUiYZnV9HrC25sCBA9t+22zVdj0RbUeItd3uuuuuVFWe8IQnDN0KO2Do+6AQdn1PfOITkzw8o83wPMRYDfHY85WvfCX333+/nwfYI1bfTLvnnnuGbgVgXdMyKmY361uYK5OPs5Iszrry1tpL1rnoG0590lp7c5I3r7Oe5SRXTKm/Y83XLck/n7U3aK2tG07OI0gVLmyPAwcO5A/+4A+GbuOUhx56KF/4whe2PeR++tOfvuX1bYeVlZU84QlPcMTLHjF0yL2yspJv/uZvzuLizL9q7BnnnXde9u/fv6XbZvW6q4E5jMUQjz1+L4O9Ze3jjJ97YKxWVlbynOc8Z+g2ujVTatFa+zdJUlXf3Fr7ynxbgp1x33335YEHHlg35P785z+/rdvzYmp7HDhwIPfee2+OHz+ec889d+h28uUvfzknTpzYtUdyeyGwt6yGn0OG3AcOHHjE/0ngYVt9A3ZlZSX79+/Peeedt41dwdYJuYF5G+Pv2QBrffWrX819993nd5MtmOl0JVX1D6rqj5P8r8n3315V18y1M5iz1V9wpv0DLkdyj9fq/P4ve3ceJsdV3/v/c7pn1ywajWartmXhRba1eO3xT3gDmwSzxo5xCITk8guG4Dyx87AZSHIvNyHkB7nBDsRASCC2cQgGfCGGgMHELDbGxkzLkpG8IXmR5K7ZNJJm37t+f7RaHkk901t1LT3v1/PokXS6u+pbp08t/a1T5/T39/scSZqb36vfCcZsbJvJUleS+vp6tba2+prkpr0tLRaLlZzk5hyEIOrs7FQkEvElyc0xB1gZSHIDCLq+vvS0glybFC/fMbk/I+kqScOS5DjOE5IuL1dQgBeWS05alqWDBw9qamrKtfUlk0mtWbNGdXV1ri1zJcp8X6WMS+smN8cQrq6uVkdHR2C2TSIpthJZluVbG6S9La/UG7CM8Yegikaj6urq8vTYQ+cDYGXp6OhQJBIJ1HU2ACzGtUnp8k1yy3Gc/ccVLbgcC+Cp5Q4gmTtnmTtpbq2Pg1XpMt9NUHphuN0TLEgTa87OzmpoaIh2u8KU2lu4WMvNk4C0zPEhPQ1J4egpjyDz+vxn27YaGhrU3Nzs2ToB+KeqqkpdXV2Buc4GgOOR5C5dvknu/caYiyU5xpgaY8yHdGToEiCslpuAqxyPs5G8cUfQHjXMxNHV1eXK8oKU5M4MCUO7XVn8aoPLzZOANMuyNDc3p+Hh4YI/y00EBJ0fSW7mAABWliBdZwPA8Uhyly6viScl3SDps5Jikl6S9CNJf1auoAAvJJNJrV69Wg0NDSe8Vq4k96ZNm4r+/M6BnfqPnf/hWjylWtuwVh945QcUMXk/EOKKtrY2VVdXB+YC1bZttbe3q6amxpXlWZalxx9/3JVllcrNoVjydWjqkD7zy89oZmEm53sbaxp188U3q7Zq6QlI5xbm9A+P/INGZ0ZLju38rvP1+5t/v+DPvXDoBX358S9rwQnHA1DTsWn19fUplUopEvFu/860t92rduujD3zUs/WGyVj9mKR0Xa1du7agzy43Se53nvmOHn3p0YKWl8/+l81CakGffuTTOjR9qKDPndd1nt62+W0FfSas5lPz+vQjn9bh6cN+h+KKa8++VhfFLsr5Psuy9Mgjj3gQUVo5hu+xx2x9ofcLmk/Nu7bM5tpm3XzxzaqOVru2zHJ47uBz+rft/6aUk/I7FGBJq05bJfvpYPyGAIDjJZNJ1a6u1T/u+EfNLsxKkrZ0bNE7znmHz5GFR15JbsdxDkiiVlFRluvR5naSe2FhQf39/SX9mPqbB/9G33r6W6qNFpZQKIeUk9Jcak6Xn3J5Xj9c3WSMCVQvDLd7RlqWpYGBAc3Pz6uqKt/7kOXhx53kr+38mj7+0MdVE62R0dK96zJt8Lyu8/SmDW9a8n0/fuHH+quf/JWqI9Ul3ZCZT82rOlqta8++tuBEw2cf+6w++9hnA7Hv5jKXmlNHXYcWFhY0NDSkzs5Oz9Zt27YUlb7Y90VF+iOqivjb/oNmPjWfvlFSla6rc889t6DPL7U/O46j6797vQ5NH1J1JL+2ndn/zuk8R79z5u8UFMcv9v9CH/3xRwvaJ+dT86qKVOnas69VTdSdG4pB9vC+h/UXP/6Lko9bQTC7MKuEndAD/+OBnO+1LEsHDhzQzMyMamvLf7y0bVs9PT2uLvNfEv+iv/v537l2vM/saxd2X6irTr/KlWWWy62P3qovJL4QinMdVqaZhRmdtv40jfx4xO9QACAr27bVdFGT/vahvz36e/gtG99CkrsAy/6CNMbcJmnJgR8dx/lz1yMCPLLc2KStra2qra11LZE6NDSkhYWFksZC7bV79fubfl9fv+7rrsRUin0j+3TKZ05Rb7LX8yS3FKxHDd1OcsdiMTmOo4GBAd/HznV7vPF89Nq96ljVof4P9i/7CPn47LhaPtWi3mTvsknu3mSvJOnAhw+oubb4cVfv3nm3/uDbf6Anh57UeV3nFfTZXrtXl5x8iR5+18NFr98rN913k+54/A5J6e/f8yR3o+TI0T+/8Z/1ngvf49m6w+D27bfr+u9eLzUWdwN2qST3C4df0PDUsL74xi/qvfH35rWsyblJNX2ySb3J3oKT3Jl9cv/796uzMb/29Y1d39DbvvU27RrcpQu6LyhofWGUqaPkB5JqX9XuczSlueF7N+jru76ulJPKmbDPnGv6+/t1yimnlDWuzPA9bp/feu1ebe7YrJ1/utOV5Y1Mj2j1369Wr90b+CR3r92rV69/tX76zp/6HQqQ1RVfuULPv/i8pzfTAKAQtm2r4ZT0SAOjHx0t+IlJ5B6TOyFpm6Q6SRdI2n3kz3li4kmE3HLJyUxvYbdm3y512IfBiUHtG9mnuBV3JZ5Sndx8stob2pXoS/iyfje/m1K5/bhzZllB2D7btlVdXa22tjbP1pmwE4pb8ZxjpDbWNOrstWfnbIOJvoTObDuzpAS3pKP7XsIurM3Pp+a1vW97YPbdXKwmSxMLE1K1923Qtm2p6eU4cKyjddJUXJJ7qfNQpk0X0kYbqhu0qX1TUeeARF9CJzefnHeCe3Fshe5/YZXoS+iUllNCn+CW0t/dyMyInjv4XM73enn+GxkZ0dTUlKvnb8dxjp7D3NJS16INbRsC3/ZnF2b1xMATineH41yHlclqsjQVnZIk9fX1+RwNAJzItm1Vt1ZrbcNaEtxFWjbJ7TjOVxzH+YqkMyRd4TjObY7j3CbpNUonuoFQSqVS6uvrW/bHjZu9hUsd9mGbvU2S1GO5+1htsYwx6on1+PajKyg9uefn5zUwMFCWJHcQts+2bXV3d3s2LvP47LiePvB03u080wYdZ8kHjpSwE+qJlb7fnL7mdLXUthTc5p8eelpT81OB2XdziTUf6dVYZG/hUti2rVVdq46NA0fFmtJ10mQ1ldST+/jJlhN2QjXRGm3p3FLQ8nqs3PtfNsXsk6e2nqrWutbAJ/rc4tZxKwgyx758vjsvz3/lGI5r/+h+DU0OuX68z+xrQbZrcJdmF2Yrpt2iMsWaYhpJpYcqCcJ1NgAslnnKzGl0jl73o3D5Zi4sHe1fJUlqPFIGhNKBAwc0Pz8fmiR3r90rIxOox7Tj3XE9NfSUJmYnPF+3ZVkaHR3V+Pi45+tebGBgQI7jVHSS28vxuLf3bVfKSeXdCy7eHdfgxKD2j+7P+ro9Zsses13pWWaMUdyKq9fuLehzmfeHqSe3JKnZnyR3k9V0bBw4KlMnpSS529raTng8u9fu1bmd5xY81nXciuvA5AHtHdmb92cOTR3SnoN7Ct4ni93/wmh4cljPH3q+YnrEbmzfqLqqury+u7AnuTPDzLh9vI9bcSXHkuobC27P03JtO+Amq8nSrDMr1QfjOhsAFhsbG9PExIRma2f5LVSCfJPcn5K03RhzpzHmTkmPS/r/yhYVUGb5/LiJxWKuJrmNMUWPb5uwEzpr7Vlqqm3K/WaP9MR6lHJS2t6/3fN1Z8bQ9PtRw3KMWd3e3q5oNBqIi2+vk9yFDpuQ6TG2VA+3TLlbPct6rB7tHNip6fnpvD+TsBNqrm3WGW1nuBJDuWUuqFpOavElyV3XUaeqSJXWNqz1dN1hsKZ+jWqiNaptL26+iGzjD6eclLbZ24rqeZpr/8tmW9+2Yz5b0PqsHu0a3KWpuamCPxsmpdRREFVHq3V+1/l5tZO2tjZVV1eHNsmdsBOqjlTr3M7CJoXNpZDe8H5J2AmtqV+jV6x+hd+hAEsqddgvACinzHFp3IyT5C5BziS3SQ+M+oCk/0fSfx7588ojw5gAoZTPGNmWZWl8fFxjY2Mlr8+2bXV0dKi6urqoz7s9xqMbLuy+UJI/P7qC0tu5HD+So9Gourq6fN82yf3xxnNJ9CV0UvNJ6mrsyuv953Seo6pI1bJJ7oiJFDxR5FLiVlxzqTntHMh/QrGEndCF3RfmnHAtKDIXVI3djZ63wWQyqWhLVN2N3aGpLy8ZY2Q1WYq0RIoaszjbTavdw7s1NjtW1PllS8cWVUeqCzoHZN6bOX8UIm7FNZ+a168Hfl3wZ8MkU0dBenKrVHErrsf7HtdCavnpfDLzoXhx7Cl1rpRsEn0Jbenc4voYmud1naeIiQQ7yd2X33wagJ8y1zjR1cHoTAIAiyWTSSkijSyMkOQuQc5fkU56sMV7HcfpdxznO0f+9HsQG1A2+fTAdXMCpGQyWXRv3+RoUn3jfYFLcnc3dSvWFPPl8fGgTM5Yjh/JUrpd+r1tExMTGhkZcbWXei69yd6C2nldVZ22dGxZsg322r3a1L5JDdUNrsSXiS3fNn90Iq6A7bvLaaltUX1VvWrW1njaBjPzJCysWuCibhlWk6WFhgUNDAxofn6+oM9mu2lVynA6tVW1OqfznILOAb12r05rPU2t9a0Fr6/Q/S+seu1enbHmDK2uW+13KK6JW3FNzE3omQPP5HyvV+c/27a1evVqNTS4c344OulkGYaZWVWzShvbNwa27U/NTWnnwM6KGWIHlStzfbH65NW+X2cDwPFs25ZWSY4cfg+VIN+uUr80xlTGc5OAXk5yd3Ut3WPUzd7CpQz7cHTIhQBOXOfX5JNB6skdiUTU0dHh6nKDMLFmZigYr3pyH54+rN0Hdxfczpea/C6TcHBzv1nXsk7tDe15t/mdAzvTE3EFcN9dytHews0RT9vg0NCQFhYWNF09zaSTy4g1xTRVNaVUKqXBwcG8P7fUJLkJO6GG6gad3X52UfH0WD3aZm9Tyknl9f5SJlQ8qfkkda7qDHRvVjdU0qSTGYVOPunVcCVunt+eO/ScDk8fLtt3V+xEr154YuAJLTgLFdduUXm6G9MTLzd0Nvh+nQ0Ax7Nt++hMiEw8Wbx8k9xXKJ3ofs4Y82tjzE5jTGU/L4qKls/wIUFKckdNVOd2uTvGoxvi3XH9Zvg3Gpke8XS9zc3Namjw/wLVtm11dXUpGo26utwgJLnLMRTLch7ve1xS4T1K41Zch6cP6/lDzx9Tvm9knw5MHnC1F3Vm8rt8k2yFjjEeFFaTpfn6eQ0ODmpubs6TdWba25jGZDXSc2EpVpOlUWdUUmHnpsHBQaVSqaxJ7vO7zldVpKqoeOJWXCMzI3ru4HO5Y5gY1L6RfUX39ix0/wuj/vF+vTT6UsX1iN3QtkGNNY0VneQu9/E+bsU1NDm05ETLfgrruQ4rT311vVrrWlXd5s3Y/wBQCNu2Vd9ZL0n05C5Bvknu10u6UNJnJH1J0h9KenO5ggLKLZ8fN24luWdnZzU0NFT0j6leu1ebOtwbcsFNmR80mYmyvOLluJ3LKdfEjJZl6eDBg5qezn+CQ7d5neTuTaYfwy50rN6lhjAoZRiGXOt7cuhJTcxO5Hxvr92rtvo2rV+93tUYyi3WnO4tLEn9/d6MTmbbtlQtTSxMcFG3DKvJ0lRqSqop7NyUbX+eT83r8b7HS9pHChlCxI1EWNyK6+kDT2t8drzoZQRZpSYLo5GoLui+IK92YlmWRkdHNT5e3u/Y7fN3b7JXdVV12tS+ybVlLnZ0X0sGb8iSXrtXnas66XWGUIg1x5h4EkAg2bat5lizJJLcpci36841kt4t6duSjKR/VzrZfVuZ4oJPdu7cqYmJ3MmbsHvuuef0ile8QgupBe3o36G51LG9FVvrWnXm2jPV2Nio7du365e//GXR68o8Um5ZlkZnRvXU0FMFfT5hJ3TNWddoampKv/71rwPzqOqaNWsUPyn9o+u7z37XsyR8bbRW53adK8uy9Jvf/Kak76ZUzz//vM4+++wl21Exzl579tEf3j/84Q+XHVKnnB577DFJ6Xb7wqEXNDAxUNb1/eTFn+jU1lPVWteqHTt25JXgb2pq0uazNqs2Wqv7dt93TDL5vt33qTpSrXM6z9FTTz2l0dHRkmM85ZRT1GP1KOWk9I0nv6GN7RuXff8j+x9JT5Y3P68dO3ZoYWH5SdeCorWqVSNO+umM//7v/9bGjctvpxseeeQRqTH979q5Wl/36yCrma1J/6MpXWf5DpX0i1/8QlJ6f+4b69Pekb3ae3ivpuan1GP1aHBwUM8//3yOpRyrqalJm87epLqqOv1gzw90auupy77/e7/5noyMLui+QM8++6wOHTpU0PrWrVt3dP/7+q6va3PH5oI+Hwbf+833FDERnd99vp555hkdPnzY75BcsXnzZvVYPfrcrz6nR/Y/suTEsmetPevo+e/+++8v25wQjuOor69PlmVpen5aT/Q/IUelXVs9tO+h9ASRiiiRSBQ8Zv5ympubde6Gc1Udqdb3d38/cEM6Pbr/UfXEejQ/P6/t27crlcpv+CLAD50NnXq29lmNjo7qwQcfVG2tuxPFAn6pra3Vueeeq0jk5XNs85eksUU/T5uOPMQehLJCNM4e0n9vfba4D4fI7t27VX9BvSImouTupPbO7pWUzrts2LDB5+jCw+STMDsyNMkrHceZOPL/VZIedRznnDLHV1bxeNxJJCr3sddi9PT0aKXUyY033qied/fonfe+84TXjIx237Rbb7nyLXriiSdcWd8DDzygzx/4vP7zmf8s+LNffvOXtevfd+kzn/mMK7G4wRijffv26TX3vka/Gf6Np+v+v7/3f/X9T39fd9xxh6frzeZ973uftvyPLbr+u9e7srw3b3izPmh9UK9+9atdWV4pWltb9aL9ojpv6dT0fPl7lb9jyzv01qq36uqrr877Mzt27NCNj9+oh/c9fMJrW0/aqi9v/bI2b3YnGbZ+/Xo9uvNRxW6N5T0G8V+/6q/VuK1RH/rQh1yJwQvr/2C9XtzwovRJSTPerbfmjBrNvmNWDd9q0OTOSe9WHCL1G+s19dYp1X69VjPPFPblGGPU39+vrXdv1QuHXzhavvum3bruyuuKOtc9/vjjet8T79NDex/K6/1bOrbo3qvu1WmnnVbwutatW6fep3pl3WJpwQnHDaNinNd1nu55zT0644wz/A7FNe985zv15g+/Wdfdc92y73v96a/XX63/K1166aWexPWv//qvevaUZ3XLo7e4srz3b32/Nu7fqPe85z2uLG+xXbt26fpHr9djycdcX7YbPnHFJ1T1aJU++tGP+h0KsKwzP3ymDjQf0PD/HPY7FMB199xzj9516DqNzaUTy8UmlQPnc1dJT//I7yg8seHmDTrQckAH/+fBo2W/93u/p29+85s+RhU8xphtjuNkffQx357cRtLiXxQLR8pQYT772c+60uMx6Iwx2rp1q25+6Gatrlutu99y99HXkqNJvfu/3q1HX3pU3/nOd/T000+XvL6GhgZdcsklevutb9cbzniDbrroprw/WxOt0WXrLtPvfux3dfrpp+u22/x/gOLXv/61PvKRj+j555/X/X94v5458Iwn63UcR2/55lv0i/2/0C233KK3vvWtnqx3KcYYvfKVr9T7fvo+tdW36avXfrWk5X2h9wv6xf5f6N7fv1cPPfSQ709VrF+/Xtv7t2t6flqffM0ndV7XeWVd30Wxi3THF9I3Lr797W+rvr5+yffu3btXN9xwg/bs2aNvj76wzAAAIABJREFUXPcN/XrgxGkitnRsUe9P0o92f/7zn9eppy7f03Q5d999t+666y611bYp8Z5EXj3boyaqS9Zdog98/QNavXq17r777pyf8dttt92mX+z7hbRBuvt7d2v1/GrP1r1TO/Xhxz6syf5J/dmf/Zne9KY3ebbuMLjvvvt0293p4//Hb/24zjGF9TPo6OjQfP28Xjj8gm7suVFv3PBGtdW36bTW07R7925dd911uv76/G7W7du3T+9973u1Z88e3f2Wu7Puf9lsbN+oZx5Lny9uueWWvJ8S+MY3vqE777xTLVUtSvxJQv3j3gyj44eN7Rv11KPpJ77+8R//UWeddZbPEZXmL//yL7Vnzx5dc9Y1+uk7f7rkDdN/2fYv+ukLP9XWt2/Vz3/+87IPV1JdXa3LLrtMl991uS7ovkB/d+XflbQ8I6OLT75Yn/jYJ1RTU6PvfOc7rsT53HPP6cYbb9SePXv0rbd+SzsHd7qyXDdFTVSXrrtUN911k9auXat///d/9zskIKsPfvCDmhye1OFVh/XAjx/Q3GylZACx0s3Ozurqq6/Wnj17NJYe7aJyEtySNLhbV155pW6++Wa/Iym7f+j7B03un9RBHdS9996r2tpa357sDqt8k9x3SHrMGJPpgnqNpH8rT0jw08UXX+x3CJ5K2An1WD163emvO1o2n5rXn//wz5WwE/rDc/5Qp5xyiivr2jeyT0OTQ3rjGW88Zn35sm1bGzZs0OteV/hn3bZu3Tp95CMfkW3buvzyyz0dc/i8rvOUsBNqbW0NRF1I6XZ0Ueyior7XxfaN7NN//ea/tHdkry677DKXoivN9x/5viTpXee/Sx2r8hsaoRS2bau+vl7XXHONjFn6XurQ0JBuuOGG9LiqTdaS45Z9x04nGq699tqSLhD279+vu+66S/39/Tr/5PML+qxt21q3bl1g2utyHn30Ud13132SpPZT2/WaU1/j2boziT2NSVdccUUo6stL09PTuu1f0klu02z0uksKr5/vPvtdSdLbt7xdF5+cPt+PjIxocnJSW7duzbvOh4eH9d73vjfn/pfNT+yfSJKuvvrqvHt0J5NJ3Xnnnerv79d5p5T3ZlsQPGA/ICldR694xSt8jqY0X/3qV/XII48oGonq1etfveT77DFb9z5zr54/9LxnPbnnFua0o3+HbrzoxpLP3xmZsb7dOn7Ztq0bb7xRtm0r1hwL3FAli9m2rVNOOYVjNwLrS1/6kh4ZekQLJy9o80Wb1dnY6XdIgGuam5tl27aa2nS0J7cUjKFJShquxHGkEVsXXPCWFXF++fA/f1g1MzVqbGws6OlmvCyvJLfjOLcaY34m6VKle3D/seM428sZGFBu0/PT2jm4UzdffOwdwapIlc7vOj+vCZIKkZksqNgJpWzb1oUXFjYpX7m4NSlnMeJWXLdvv10LqQVFI1HP13+8idkJPTn0pK4565qSl7V4ErdXtAYjsdFr92pdyzpPEtzSywmC5RLcktTW1qbq6uqcbdC2bUWjUbW3t5cU1+I2f/LJJxf02XJNUFoOlmVJRx7mSY4lPV23PWarNlKrmemZ0NSXlyzLkmal+ki97LHijr29yV5FTfSYpzKKmWR2zZo1qq2tLeocUMz6Fu9/bt14DrJMHXV3d/scSekyk0Q7jrPscX3x+e+MNm+Gatk1uEszCzOuTvTp9vG+o6NDkUgkFJPkZW7oAkFlWZZGHx2VLkhf45DkRiXJnG9H/8nvSNx18OAhtd24cn4b2GO2Vo+vXjHbWw7ZZ37JwnGcxx3H+SfHcT5LghuV4In+JzSfmleP1XPCaz1Wj7b3bdd8yr2JgxJ2QtWRap3beW7Bn52bm9Pg4GDZJmEqVEtLixoaGnz50dVj9WhibsKzIVJy2dG/QyknlbUdFWpzR3oSxYQdnHHxM087eMW27bzaeSQSOXoxl2t53d3dikZLuyGSianYpF5Q9t1cYrGYdGSUgGITqcWyx2w1m+aX48AxMnXSbJpljxf33ST6EtrUsemYiYIzbbqQOjfG5LX/ZWPbtlpbW5cdjuh4pex/YWTbttra2lRXV+d3KCWLxWKamZnJOdHoxvaNqq+q9/T8l1mXm+c4t4/3VVVV6urqCkXbD9O5DitTLBbTZH96zg+vr3GAcovFYqE4VxSqmOvUsJqZn9Hw1LDmDs6tiO0tl7yT3EClyfTUztaDJ27FNTU/paeGnnJ1fVs6t6i2qvBZvPv7++U4TmDu6GUSHMmktz09pWN7ewVBJo4LrdJ72ddEa3Ru17mB2baDUwf13KHnXO3llksymcy7nefTBgtZXq51ZZZXiPn5eQ0MDARm380l01u4IdLgS5K7YSGdfGXsuRN1dnbKGKO6+bqivhvHcdSb7FW8+9j9OdOmC22jxZ4DiunpWuz+F1Zhevojl3y/u6pIlc7vdv8puuX02r1aXbdap7YWP1/D8dw65yzm1/VWIWZmZjQ0NFQx7RaVybIsaSz9b5LcqDTFdj4IumKvU8Oob7xPkjQ5MLkitrdcSHJjxUrYCXWs6tBJzSed8FomqedWjyLHcZSwEyckF/JVzOPd5ebXiXRD2wY11jQGprdzwk4UPCbtcuLdcW2ztynlpFxZXim22dskFT/ETqEcxykouZNvT2439pu1a9eqqqqq4DY/MDCgVCoVqH13OZk4m02zL0nu6FR6aJmamhpP1x0GVVVV6uzsVNVkVVHfzd6RvRqeGj5hfy52aIxizwHFJAHzHZ6oUpQjUeqXQoY3i3fH9Xjf41pILeR8rxsSdkJxK55zeKx8jY2NaWxsrCxJ7qC3/f7+9GSwldJuUZksy5LG0xPFkuRGpcmcK1Ip/39DuimIeZByyRyXRl4aWRHbWy4kubFiZYZhyPbj5oy2M9Rc2+xaIvW5Q89pZGZEPbHiHokN4sHdrx9d0UhUF3ZfGKgkt5uPOvfEejQ2O6bdw7tdW2axMnV8Ybc3Y8GPjIxoamoqkEnuSCSi7u7ugtt8EPfd5bS3tysajapurrjewsVyHEf2mC1nJDhPrASRZVlKjaTSdeU4BX326NAMx52HbNtWS0uLVq1aVXAsxQ5XUuh3XMrwKGFUiT258/nuemI9mpyb9GQ4ssy8LG6ev/v60j2wVmKSO2znOqxMlmVJKak56v2NfKDcLMvS3NychoeH/Q7FVZU0T0kumePS3ME5zqclIMmNFWl8dlxPH3h6yR6qERPRhd0XuvbYrBuTTkrB+vGweDIpr8WtuHb079Dswqzn615sZHpEzw4/62pP5yANx9Jr9+r0Naertb7Vk/UV2s4ty9LIyIgmJiayvj49Pa2DBw+6tt8Uk2gI4r67nGg0qq6uLkUno55OPDk6M6qJuQnNDs+Gpq78YFmWZg7MaHp+Woemlx/j+Hi9yV5VR6q1pWPLMeXFJlQtyzraczVfqVRKfX19Ra8v6Ik+NywsLKi/v79i9oPMj9K8enJ7eP7LzMvi9qSTUnmS3MPDw5qZmXF1uW4K27kOK1OmfTY6jZ5Prg2UWyE3lcOkmLlcwio5euS4NMr5tBQkubEibe/bnnOywB6rR0/0P6GZ+dJ/VCTshOqq6rSpfVNRn7dtW9FoVB0dHSXH4hbLsjQ5OanR0VHP191j9WhmYUZPDj7p+boXe7zv8aPxuOXstWerobohED3V/Zh0Usp/YpHM+zK9547ndq+6YiZ0CeNkKZnewn1jfZ4Nm5PpuTDeNx6quvJaLBbTWF86qVxoL7REX0Lndp17wrwQxU4Wl2v/y2ZoaEgLCwtFr6/SfrhlMzg4qFQqVTH7QV1dndasWZPXd7ehbYOaapo8Of+Va9JJyf0fpsXsa14L47kOK09LS4vq6+tVO1tLT25UnEqdpHslTWpsj9mqNtXSFOfTUpDkxop0dBiGZSYLjFtxzaXmtGtwV+nr60vovK7zVB2tLurzyWRS3d3dikSCs8v6ORGY22OmFyufdlSoaCSqC7ov8H3bBsYHtH90v+eTTkqF9eRe/LlSl5fP+gpt77ZtKxKJBOoGVS6WZWl6aFpzqTkNT3rzyCNj0OXHsiyNJQtPcqeclLbZ27LOC1Hs+M/FnANKSQKGYfI9N1Rij9h8v7uIiehCy5vhyBJ9S8/LUqxyTY4VholXk8mkqqur1dbW5ncowJIyQ19pnIknUXkqtSd3Jc1Tkos9bqsl0iKpsq4DvRacjBngoV67Vyc1n6Suxq4l3+PWY7MLqYUlkwv5CuL4nH6eSE9tPVWtda2+D+nRa/dq/er1Wtuw1tXlZibfmk/Nu7rcQmSSDF4muQsdcy1XG3Q7WWRZlg4fPqzJycm8P2Pbdnr4j2jUlRi8YFmWxuziegsX6+h6eDxvWZZlSUdGBynku9lzcI9GZkZO2J9LHT5EKuwcUGqSe3R0VOPj4wV/NkwqNcmdbzuJd3szHFlvstfVSSel9He3atUqNTU1ubZMKRyJi8x1qpv1CZSDZVmaPzSvwYlBzS3M+R0O4JqurnReI8jnimIEMQ9SLvaYrYaFBkkrYwzycqnyOwAEy+u++jrt6N/hdxhlNzw1rDdteNOy71m/er3a6tv0wR99UH/9s78uel0pJ6WJuYmSkoW2beuMM84o+vPl4OcjUcYYxa247txxp7777Hc9X3/G8NSwrjnrGteX2xPr0Wce+4y6b+lW1PiTHJ2cm5SR0QXdF3i2zkInwMs3ye3W416Z9fX19em0007L6zNhvDCLxWIa/146kXjFV65QTbSm7OucmDsyrvp4ZSX33LY4yX3TD27SRx/4aF6fm1lID7t1/HloeHhYc3PFTW7jR5JbSu9/QTsfuqkSk9yxWExPPpnf8GI9sfRwZLFbY2U9/w1MDOgtZ7/F1WVmHql2O9EbpiQ3EHSxWEzPDDwjvUKK3RpTxNDnD5WhtqpWLRtbAn2uKFRmnpJnTn5GXZ9eunNipTgweUDrp9drzZo1qqur8zuc0CLJjWO86pRXaf3q9X6HUXZGRn98/h8v/x5jdNvrb9ODex8seX31VfUlJUNt29arXvWqkuNwUyGTSZXDx171MZ3aeqov684wMrr+gutdX+6bN7xZ79/6fk3O5d9juBy2dGxRY02jZ+sr9Edyc3OzGhoalk1y19bWqrXVnYkzFycaCklyr1+/3pX1e8WyLCkpvXfTeyUPr69m+2Z1x+wdJEqWYVmWNC/9cfcfq8Yq7OZDV2OXtnSeOOnk0eUWqKmpSY2NjUUluTO9jQqxeP+r9CS3MUadnZ1+h+Iay7LU39+vhYWFnE+1vOGMN+gDWz/w8o2vMqmOVOtd57/L1WWWK9Hb1tam6urqQCcubNvWxo0b/Q4DyMmyLI0/MK6b/vwm3yewB9wytzCn23fcru4zuwN9rihUZi6XF2teVGNNo37r1N/yO6Sye/rup1VvVf4km+VEkhvH+IvL/sLvEALl7VverrdvebuvMUxNTenQoUOBS/ysWrVKLS3+3S2+dN2lunTdpb6su9yaapt061W3+h2G5wpNEGTGVlwuye3m49PF9KZLJpO6+OKLXVm/VyzLklLSH3X/kS655BLP1vuFL3xBd4gk93IydXP+zPm66U03lby8UnsNFzIMhZTeHzo6OlRdXfj8FGHozeqGZDKpzs5OVVVVziW6ZVlaWFjQ0NBQzhscjTWNuuWqWzyKzF22bWvr1q2uLzfXuS4IbNvWb/1W5ScfEH6WZWnqwJT+9uK/VUtLi9/hAK5wHEdf3flV1bXXKbktuPM3FCpz3ht1RnXd6dfptjfc5nNE5XfRxy/it1CJeD4HCLi+vj5JwZxhN+g/uhAuxcyeHYvFcia53VLoED0zMzMaHh4O5L67HL+SibZtKxqNhmqSTq+tXbvW1R6dpQ7ps9z+t9T6SllXZhmVrJQ6CqqVcIPCcZyyDtlR6L7mpYmJCY2MjFRcu0VlWgnHI6w8xhhZTZYiLZGKatu2bUvV0mRqUlbTykj8VuJ1oNdIcgMBl0ym78YG8Y6eZVlH4wNKkUqlikoQLNcG3Z6Nu6WlRfX19Xm3+cwNqiDuu8vJxOv1vh3GSTq9FolE1N3t3qOome+4mOFDpMLPAaUkAZuamrRq1aqKP+dU4tjGfh1TvHTo0CFNT0+X7bsL8vVWJY4jj8q1Eo5HWJmsJksLDQsaGBjQ/Py83+G4IplMSkfmcl4JSe7MGOScT0tDkhsIuCD/eKAnN9xy4MABzc/PF5Xktm1bjuOc8JrbyaJCHxkP8r67nDVr1qimpsaXntxhqys/uHnctW1b7e3tqqkpbnLR5fa/pdZX7HcchiEb3FCJ+8FK6DlZ7uN9kNt+WM91WJlWwvEIK1OsKaapqimlUikNDg76HY4rbNuWmtP/jjVXfu/mzBjknE9LQ5IbCLgg/3iwLEt9fX1KpVJ+h4KQK7adW5alqakpjYyMHFM+Njam8fFx1/eblZDk9iuZWInJvXJwO8ldSp1blqWZmRkdOnQo53vn5uY0ODhY8voqOTExOzuroaGhitsPOjs7ZYyp6O/OiyT32NiYxsbGyrL8UoT1XIeViSQ3KpXVZGnUGZVUOe3btm01x9JZ7pXQk5vzqTtIcgMBZ9u2amtr1dra6ncoJ4jFYpqbm9Pw8LDfoSDkSklyL/788ctze0yzlZDklvwZ/5Ukd36CluTOLCeXgYEBOY5DknsZ/f39ksJ5zFhOdXW1Ojs7K/q7K9c5JyPTJjLDYAVJmM91WHlWrVqllpaWij4eYWWymixNpaakmspKcjd2N0oiyY38keQGAi6ThDDG+B3KCegNAbeUK8ldrp7c+QzPYNu2ampq1NbW5moMXvA6mZiZpJOLutwsy9Lhw4c1OTlZ8rK8THK7sU8WOjxK2FTyj5tKv0GR2bbu7u6yLD/I11u2bauhoUHNzc1+hwLkpdKPR1iZjiaBm4J5riiGbduqXVur+qp6tdS2+B1O2VXydaCXSHIDAZdMJgM7wy6Tt8AtmTZUaIIgs28c3wbLNWFrLBbTxMSERkdHc743M/FlEG9Q5eL1JGfl7gVZSTJ1VOoPmPn5eQ0MDJRU50vtf9lk3lPq+qampnT48OGilxFkbtRRUAV54kQ3JJNJtba2qr6+vizLL2Rf81rmOjWM5zqsTJV+PMLKlElymxZTMe07mUwq0hyR1RTO31OFSiaTMsYUPSE80khyAwEX5Ef4g9yzCOFS7AR4maS4lz25s60vmyDvu7lYlqXx8XHPxn+l50L+3DruDgwMKJVKlVTnS+1/2bjVkzvf9YVRJe8Hld5zstzH+yC3/TCf67AyVfrxCCtTrCl9M7TlpMoYjiczT8l8w/yKmHRSSp9POzs7VVVV5XcooUbtAQHmOI5s29Yb3/hGv0PJKnOXsRJOpPBXsT+SGxoatHr16qxJ7sbGRjU1NbkVoqRjEw1nn332su+1bVubN292df1Fab5KGstzaIumBmn0/mO288wzzyxjcDq6Hkmyrv0bafITS8YVeLnqerntWPzZzPuylLmV7Dpa5+//onTDV/OL8Th1dXVas2ZN3knuaDSq9vb2ouKVjt3/Nm3aVPRygsq2bVVXV4dyiKNcLMvS0NCQZmdnC76ZGQblTvQ2NTVp1apVgbzesm1bF110kd9hAHmzLEt9fX1KpVKKROjzh8qQ6cnd2NUYyHNFoTLzlExGJ1fEeNwSN43dQpIbx/jkJz+pvXv3+h0GjlhYWNDExET6YFdIokpKJyqkYz+TrawEtZLWmmrdc889FXEyhX9+9atf6cILLyy8nUuyInP6wQ9+oBtuuOFo2U9+8pPi9ptc69KUJOlTn/qU7rnnnmXf++KLL+q1r32t6zGU1dikZC6TVZ/ezo985COePDL31FNPSZKsyZSk6JJxhV6+25HtfZnvRvOSpM997nP62c9+VnQo+/fvlyRZU0XGeIQVmdUPf/jDY/a/bB566CF1d3crsvr1Re8Pmf3v7//+7/Wtb32rqGUE2YMPPlhyHQWVVXtQkvTud79bDQ0NPkfjvmeeeUa/+7u/W7bjvZFkGUff//73NTV1/E7rr/379+uaa64J17nOb/leo7t83Y40q3ZIc3Nzeve7312RN92wMtXW1mpV5yrVtNVo20+35bwuC7oDBw5IkkadUU0NToV+e/KRSCTSN42znU/D0uEnAEhy4xgPPvigduzY4XcYWOTkk0/WpZdeKo19t7APZrsgLsNF8tXOGn1vaEj33nuv68vGymGM0ete9zrpB8snjrN5U2q1vjI+fkIbfMc73iHd+iu3QpQknaJaxdWonTt3aufOncu+d82aNbryyiulf3rc1Ri8cM5Ulc4880z98pe/9Gydl19+udY8tODZ+sKqRVFdoRY9tWeP9uzZU9KyNm/erA276kpaxptSq3XHxERe54Brr71W+ufl95vlnKxa9ahRu3bt0q5du4peTpBdd9110uef8DsM171yplbr16/Xj370I79DKYuGhgb99m//tvSVL5ZtHW92Vus/RkcDd721du1aXXHFFdItj/kdSnjke41OcrssLpmp17p163Tffff5HQrgilQqpaGhIXX8bYdWr1utiUh+12VBd+rGU/V86nn1/qRXw/81rNWrV/sdUlkd/T38va+f+CLng7yZSp2hPh/xeNxJJBJ+hwHkp9BejF71COGuItxUTG/d5dpguXr/Oj/P/71h7YFcyDa6Jax15Qe3vh836tzr/cGPtumlSuwRu1KuFcr93QW57XP8zh89uf0X5H0JKND8/Lxqamq07mPrdNK6k/Twux72OyRXPDX0lDZ9YZOa/7tZbz37rfrSl77kd0jeoCd3TsaYbY7jxLO9Rk9uICyaGvK7yM33AJht/FfAb9naeSntc/HyCl3OUsmKpgIftc933z3+M0uMyexJAqzQbXRzvfyYz83N76fUOi9lfyimTfvVNr20+DgV1IQ31w3ZFVonldT2y3G+rTSl7DcrpY68EPR9CShQVVVVesLCySrZY5UzhGhmW0aTo7Jes4LGqub6qiQkuYGwcPtgx8ETQRSkdu5WLG7HUMn7biVvW1B5XecrrU2XirqpbJX0/QbhfFvJqCMAy7AsS4dGDslutuU4jowxfodUsqMJ+1ExISPyxnTCAAAAAAAAQAhZlqWZAzOaWZjRoelDfofjiuRoMv2PMZLcyB9JbgAAAAAAACCEYrGYxvrGJKlihiyxx2w1RBqkufT2AfkgyQ0AAAAAAACEkGVZGktWWJJ73FazaZZET27kjyQ3AAAAAAAAEEKWZUnpHHflJLnHbNXN1Skajaq9vd3vcBASJLkBAAAAAACAEKrUJHd0Mqquri5Fo1G/w0FIkOQGAAAAAAAAQsiyLGleaow2vjxhY4ilnJTsMVupwymGKkFBSHIDAAAAAAAAIZSZmLFJTbLHw9+T+8DkAc2n5jU9NM2kkyhIld8BAAAAAAAAAChcW1ubqqurVTdbp2cPPKsf7vmh3yGV5MXDL0qSRu1RWT305Eb+SHIDAAAAAAAAIRSJRNTd3a2a8Ro9HX1ar/+P1/sdkism9k3IupokN/JHkhsAAAAAAAAIKcuyVP9kve78tzv9DsUVhwcP6/V//XrG5EZBSHIDAAAAAAAAIWVZlp555hltPWmr36G44uEXH5YkktwoCBNPAgAAAAAAACFlWZaSyaTfYbjGttMTaJLkRiFIcgMAAAAAAAAhFYvFNDIyoomJCb9DcUUmyR2LxXyOBGFCkhsAAAAAAAAIqUyP576+Pp8jcUcymVRtba1aW1v9DgUhQpIbAAAAAAAACKlMkjvTAzrsbNuWZVkyxvgdCkKEJDcAAAAAAAAQUpWa5AYKQZIbAAAAAAAACCmS3ABJbgAAAAAAACC0Wlpa1NDQUFFJbiadRKFIcgMAAAAAAAAhZYyRZVlKJpN+h1Ky0dFRjY+P05MbBSPJDQAAAAAAAISYZVkV0ZM7sw0kuVGoKr8DQMA0XyWNTUpNDceWl7NsbPLl8iCUebnt+ZZRR5VRb9nK2Pb8t8ntsqDVR7nKgirs8XuBOiqO2/UW1DoP0nFmJddRJaKOyot6y406yo06ym0F1lGsao/unu9XXV2d36GUJJVKSTqS5D4+R+XWdxeka6Z8fjeP3r/89kCSZBzH8TsG38TjcSeRSPgdRrCYy/yOAAAAAAAAAAX4tSb0tY+81u8wXNHc3KwPfehDqql9jd+hBIPzc78jCAxjzDbHceLZXqMnN47V1EBvSr97l2Yro44qo96ylbHt+W+T22VBq49ylQVV2OP3AnVUHHpyB6MsCFbKdrqNOiov6i036ig36ii3FVhH5zS165xPfcrvMNx1fI5qpfbkRl5IcuNYPAIBAAAAAAAAv5GjQgGYeBIAAAAAAAAAEFokuQEAAAAAAAAAoUWSGwAAAAAAAAAQWiS5AQAAAAAAAAChRZIbAAAAAAAAABBaJLkBAAAAAAAAAKFFkhsAAAAAAAAAEFokuQEAAAAAAAAAoUWSGwAAAAAAAAAQWiS5AQAAAAAAAAChRZIbAAAAAAAAABBaJLkBAAAAAAAAAKFFkhsAAAAAAAAAEFokuQEAAAAAAAAAoUWSGwAAAAAAAAAQWiS5AQAAAAAAAAChVeV3APBZ81XS2KTfUQAAAAAAAABYTlODNHq/31EEEj25VzoS3AAAAAAAAEDwkcdbEkluAAAAAAAAAEBokeQGAAAAAAAAAIQWSW4AAAAAAAAAQGiR5AYAAAAAAAAAhBZJbgAAAAAAAABAaJHkBgAAAAAAAACEFkluAAAAAAAAAEBokeQGAAAAAAAAAIQWSe6VrqnB7wgAAAAAAAAA5EIeb0lVfgcAn43e73cEAIBK1HyVNDbpdxQAAADwS1MDOQcAniHJDQAA3McPGgAAAACARxiuBAAAAAAAAAAQWiS5AQAAAAAAAAChRZIbAAAAAAAAABBaJLkBAAAAAAAAAKFFkhsAAAAAAAAAEFokuQEAAAAAAAAAoUWSGwDK/NzNAAAgAElEQVQAAAAAAAAQWiS5AQAAAAAAAAChRZIbAAAAAAAAABBaJLkBAAAAAAAAAKFFkhsAAAAAAAAAEFokuQEAAAAAAAAAoUWSGwAAAAAAAAAQWiS5AQAAAAAAAAChVbYktzHmdmPMoDFm13HlNxljnjXGPGmM+T9HytqMMT81xowbYz636L1Nxpgdi/4cMMZ8Jsu61htjpha974vl2i4AAAAAAAAAQHBUlXHZd0r6nKS7MgXGmCskXS3pHMdxZowxHUdempb0vyRtPvJHkuQ4zpik8xZ9fpukby+xvuccxzlvidcAAAAAAAAAABWobElux3EeMsasP674TyV9ynGcmSPvGTzy94Skh40xpy+1PGPMGZI6JP28LAEjrfkqaWzS7yjKq6kh/ffi7XSrrJzLruSyIMQQ9LIgxBD0siDEEMayIMQQ9LIgxBD0siDEEPSyIMQQxrIgxBD0siDEEPSyIMQQ9LIgxBDGsiDEEPSyIMTgZVkQhD3+oPO6LpsapNH73V9uBTKO45Rv4ekk9/ccx9l85P87JH1H0uuU7r39Icdxehe9//+VFHcc58Ysy/qYpGbHcT60xHqelPQbSaOS/qfjOFmT4caYP5H0J5K0bt26C/fu3Vv09lUkc5nfEQAAAAAAAACQpOwpzhXJGLPNcZx4tte8nniySlKrpK2Sbpb0TWOMyfOzb5N09xKv9Ula5zjO+ZI+IOlrxpjmbG90HOdfHceJO44Tb29vLyz6lSBz96mSNTWcuJ1ulZVz2ZVcFoQYgl4WhBiCXhaEGMJYFoQYgl4WhBiCXhaEGIJeFoQYwlgWhBiCXhaEGIJeFoQYgl4WhBjCWBaEGIJeFoQYvCwLgrDHH3Re1yXfUd7KOSZ3Ni9J+raT7j7+K2NMStJaSUPLfcgYc66kKsdxtmV7/cjwJ5khULYZY56TtEFSws3gVwQegQAAAAAAAAAQIl735L5X0pWSZIzZIKlG0oE8Pvd2Ld2LW8aYdmNM9Mi/T5V0hqTnS44WAAAAAAAAABBoZevJbYy5W9KrJa01xrwk6X9Lul3S7caYXZJmJb3zSK9uGWNelNQsqcYYc42k1zqO89SRxb1V0huOW/7vKD1+98ckXS7p48aYeUkLkm5wHOdgubYNAAAAAAAAABAMZZ14Muji8biTSDCiCQAAAAAAAAAEWZAmngQAAAAAAAAAwDUkuQEAAAAAAAAAoUWSGwAAAAAAAAAQWiS5AQAAAAAAAAChRZIbAAAAAAAAABBaJLkBAAAAAAAAAKFFkhsAAAAAAAAAEFokuQEAAAAAAAAAoUWSGwAAAAAAAAAQWiS5AQAAAAAAAAChRZIbAAAAAAAAABBaJLkBAAAAAAAAAKFFkhsAAAAAAAAAEFokuQEAAAAAAAAAoUWSGwAAAAAAAAAQWiS5AQAAAAAAAAChRZIbAAAAAAAAABBaJLkBAAAAAAAAAKFV5XcACJjmq6SxSW/W1dSQ/nvx+twqy/w7Iwxl2ZSzjtwoC4Ig1UdQ6y1I2x7UOsomSPVBHVFHXpYFQZDqgzqijspVFgRBqo9S6i3f3wZerc/vsnIK0nYGtY7yFaT6oI6oNy/LgiBI9ZGrjpoapNH7s7+GYxjHcfyOwTfxeNxJJBJ+hxEs5jK/I3BP5kAhHXtxG7SyoB3sAQAAAAAAEAzOz/2OIDCMMdscx4lne42e3DhWU0Nl9AII052u5XrPB+lOIndgw1tvQdr2oNZRNkGqD+qIOvKyLAiCVB/UEXVUrrIgCFJ9lFJv+fw28HJ9fpeVU5C2M6h1lK8g1Qd1RL15WRYEQaqPXHWUeR05keTGscKSGK4k1DkAAAAAAABQNCaeBAAAAAAAAACEFkluAAAAAAAAAEBokeQGAAAAAAAAAIQWSW4AAAAAAAAAQGiR5AYAAAAAAAAAhBZJbgAAAAAAAABAaJHkBgAAAAAAAACEFkluAAAAAAAAAEBokeQGAAAAAAAAAIQWSW4AAAAAAAAAQGiR5AYAAAAAAAAAhBZJbgAAAAAAAABAaJHkBgAAAAAAAACEFkluAAAAAAAAAEBokeQGAAAAAAAAAIQWSW4AAAAAAAAAQGiR5AYAAAAAAAAAhBZJbgAAAAAAAABAaJHkBgAAAAAAAACEFkluAAAAAAAAAEBoVfkdAAKm+SppbFJqaji2vJxlY5MvlwehzMttz7eMOgpfvfm97ceXjd6vssscPzLCVkdLleVTh4VueyllxWyTF98/kE3zVS//u9zHqOOvYSrtOL5UGdcI4a4jt47P+e5rhZS5sZ2cf/JXynVUvvWc7bce39Gx/Pg9nK2s3MejbN97Kdu+EttROY67bpcF7fxXSlkQYvCrjPNp3ozjOH7H4Jt4PO4kEgm/wwgWc5nfEQAoh8UXP6VcvC6+mDu+bPFJuVItVUdB3/ZMjH5faEu529FSZUGJ34uySqqjfPcNN45RQd8PgWzcOj4Htf27sW9XSlk5r6PybUfZ1sE1wso8l2T73r1og16UedWOVkpbQTA4P/c7gsAwxmxzHCee7TV6cuNYfpycgniXrNRtcruMOgpfvfm97cuVlcvxF3thrqOl2tFSCt32UsqC9r0DyykmwVXKutw8B/h97Mm3jGuE8NeRG4rZ18pdb5yHClPqdVQh6+C7WZofv4ezlXlxPDpeqdu+0pTjuOt2WdDOf6WUBSEGv8pW+r5WAHpy05MbAAAAAAAAAAJtuZ7cTDwJAAAAAAAAAAgtktwAAAAAAAAAgNAiyQ0AAAAAAAAACC2S3AAAAAAAAACA0CLJDQAAAAAAAAAILZLcAAAAAAAAAIDQIskNAAAAAAAAAAgtktwAAAAAAAAAgNAiyQ0AAAAAAAAACC2S3AAAAAAAAACA0CLJDQAAAAAAAAAILZLcAAAAAAAAAIDQIskNAAAAAAAAAAgtktwAAAAAAAAAgNAiyQ0AAAAAAAAACC2S3AAAAAAAAACA0CLJDQAAAAAAAAAILZLcAAAAAAAAAIDQIskNAAAAAAAAAAgtktwAAAAAAAAAgNAiyQ0AAAAAAAAACK0qvwNAwDRfJY1NSk0Nx5aXs2xs8uXyUstG78++XWHRfNXL/86njnJtc2Z5o/cfu2yvygrZjuVeD2NZvvtBocvL9zO51huEOiql7Phtkk5sg7m2M/OZcskcT49fbyUet4LSPsJel25b7rsp5vxdSv0Wc33hxvd5/Hq9OrYXetzN531Bat+lXF8Usx1LHduzlQXleJStzIvvsNg2n8E1OvCyQo49bpcF6To7qGVBOba7URaEGLws81qQtr3Y9sF5NC8kuXGszE6V7QAUxrKwOX4bcm1n0Lc53/YUpDbjVlmhbXQl1lEpZdkuerO9189jRaH7c1gVu52cA8pvue/G63p14/rCr/UG9Vi8kgT5OBO07zAs1/JAGFTqsSdM57qVUhaEGLws81qQtt2t9oGsSHLjWE0N2ZNH5SxbvMO6URZmi7chnzrKtc2L7/Zlu/NX7rJ8exMF4e6o22X57geFLq/Q/cDr/c/L+l2uDebT9sotczw9fr2VeNwKUvvAy5b7boo9f5cai9/r9erYXuhxt9D3+c2t64t8LXV9lK0sSMcjP889blw3hG3bAbcVcuxxu8zv6+xybJPbZUE6trtV50GLq1xlXgvStruxT2JJxnEcv2PwTTwedxKJhN9hAAAAAAAAAACWYYzZ5jhOPNtrTDwJAAAAAAAAAAgtktwAAAAAAAAAgNAiyQ0AAAAAAAAACC2S3AAAAAAAAACA0CLJDQAAAAAAAAAILZLcAAAAAAAAAIDQIskNAAAAAAAAAAgtktwAAAAAAAAAgNAiyQ0AAAAAAAAACC2S3AAAAAAAAACA0CLJDQAAAAAAAAAILZLcAAAAAAAAAIDQIskNAAAAAAAAAAgtktwAAAAAAAAAgNAiyQ0AAAAAAAAACC2S3AAAAAAAAACA0CLJDQAAAAAAAAAILZLcAAAAAAAAAIDQIskNAAAAAAAAAAgtktwAAAAAAAAAgNAiyQ0AAAAAAAAACK0qvwNAwDRfJY1NSk0Nx5YHpWz0/nSMi+VTFpT4vSijjl4uG5t8uXy5Mmnl1lEhZbQt6siNMuqIOipXGfVGHblRRh1RR+Uqo96oIzfKqCPqqFxl1Fuw62j0fiE3enIDAAAAAAAAAELLOI7jdwy+icfjTiKR8DsMAAAAAAAAAMAyjDHbHMeJZ3uNntwAAAAAAAAAgNAiyQ0AAAAAAAAACC2S3AAAAAAAAACA0CLJDQAAAAAAAAAILZLcAAAAAAAAAIDQIskNAAAAAAAAAAgtktwAAAAAAAAAgNAiyQ0AAAAAAAAACC2S3AAAAAAAAACA0CLJDQAAAAAAAAAILZLcAAAAAAAAAIDQIskNAAAAAAAAAAgtktwAAAAAAAAAgNAiyQ0AAAAAAAAACC2S3AAAAAAAAACA0CLJDQAAAAAAAAAILZLcAAAAAAAAAIDQIskNAAAAAAAAAAgtktwAAAAAAAAAgNAqW5LbGHO7MWbQGLPruPKbjDHPGmOeNMb8nyNlbcaYnxpjxo0xnzvu/T878v4dR/50LLG+vzDG7Dny3qvKtV0AAAAAAAAAgOCoKuOy75T0OUl3ZQqMMVdIulrSOY7jzCxKWE9L+l+SNh/5c7x3OI6TWGpFxpiNkt4maZMkS9IDxpgNjuMsuLEhAAAAQFbNV0ljk35HAZRHU4M0er/fUQAAKh3XU8vjfJyXsiW5Hcd5yBiz/rjiP5X0KcdxZo68Z/DI3xOSHjbGnF7k6q6W9PUjy33BGLNH0kWSHi1yeStXWA4sTQ3pvxfHmq1sJaOOcqOOikO95UYd5UYd5UYdFYd6A9wzNimZy7K/xr5WHOotN+ooN+ooN+oIlYQ2m5dy9uTOZoOky4wxf6d07+0POY7Tm8fn7jDGLEj6lqRPOI7jHPd6TNIvF/3/pSNlJzDG/ImkP5GkdevWFRj+ChCWHSdbnGGJ3SvUUW7UUXGot9yoo9yoo9yoo+JQb4A32NeKQ73lRh3lRh3lRh0BK47XE09WSWqVtFXSzZK+aYwxOT7zDsdxtki67MifP8rynmzLOD4Rni50nH91HCfuOE68vb09/8hXisydzaBrajgx1mxlKxl1lBt1VBzqLTfqKDfqKDfqqDjUG+AN9rXiUG+5UUe5UUe5UUfAiuN1T+6XJH37SE/sXxljUpLWShpa6gOO4ySP/D1mjPma0sOQ3HXc216SdPKi/58kyXYz8BWDMX4AAADyF5ah3oBiMAYoAMALXE8tj5szefE6yX2vpCsl/cwYs0FSjaQDS73ZGFMlabXjOAeMMdWS3iTpgSxv/a6krxljblV64skzJP3K7eABAACAY5AABAAAKA3XU3BB2ZLcxpi7Jb1a0lpjzEuS/rek2yXdbozZJWlW0jsz42sbY16U1CypxhhzjaTXStor6f4jCe6o0gnuLx15/+9IijuO8zHHcZ40xvz/7d1/sKV3XR/w90fWON2yS2ITOlrTggzp1MlIKFdgbKHIWNbGKWBbq7ajQRitiEyxA63WCg62NcMPqw6tDC2pONMGYpuxOK2zTZ1AplTBuzSWBEIJQmskQ8BodulqMiSf/nGedW+We/fe3b33nud77us1c+c++3mec873+Zzzvc/e933Oc25J8tEkX0zyqu5+dK/2DQAAAACAeagv/QzHg2Ntba3X19eXPQwAAAAAAM6jqk5099pm6/b7gycBAAAAAGDXCLkBAAAAABiWkBsAAAAAgGEJuQEAAAAAGJaQGwAAAACAYQm5AQAAAAAYlpAbAAAAAIBhCbkBAAAAABiWkBsAAAAAgGEJuQEAAAAAGJaQGwAAAACAYQm5AQAAAAAYlpAbAAAAAIBhCbkBAAAAABiWkBsAAAAAgGEJuQEAAAAAGJaQGwAAAACAYQm5AQAAAAAY1qFlD4CZOXosOXU6OXL48fW51E4eX4xxo53U5jL+/ajpkR7tVU3f9Gg3anqkR3tV0zc92o2aHunRXtX0TY92o6ZHerRXNX2bd49OHg/bcyY3AAAAAADDqu5e9hiWZm1trdfX15c9DAAAAAAAzqOqTnT32mbrnMkNAAAAAMCwhNwAAAAAAAxLyA0AAAAAwLCE3AAAAAAADEvIDQAAAADAsITcAAAAAAAMS8gNAAAAAMCwhNwAAAAAAAxLyA0AAAAAwLCE3AAAAAAADEvIDQAAAADAsITcAAAAAAAMS8gNAAAAAMCwhNwAAAAAAAxLyA0AAAAAwLCE3AAAAAAADEvIDQAAAADAsITcAAAAAAAMS8gNAAAAAMCwhNwAAAAAAAxLyA0AAAAAwLAOLXsAzMjRY8mp08seBQAAAACQJEcOJyePL3sUs+dMbs4ScAMAAADAfMjrdkTIDQAAAADAsITcnHXk8LJHAAAAAACcIa/bEdfk5izX9wEAAAAABuNMbgAAAAAAhiXkBgAAAABgWEJuAAAAAACGJeQGAAAAAGBYQm4AAAAAAIYl5AYAAAAAYFhCbgAAAAAAhiXkBgAAAABgWEJuAAAAAACGJeQGAAAAAGBYQm4AAAAAAIYl5AYAAAAAYFhCbgAAAAAAhiXkBgAAAABgWEJuAAAAAACGJeQGAAAAAGBYQm4AAAAAAIYl5AYAAAAAYFhCbgAAAAAAhiXkBgAAAABgWIeWPQBm5uix5NTp5Mjhx9fnUjt5fDHGjXZSm8v496OmR3q0VzV906PdqOmRHu1VTd/0aDdqeqRHe1XTNz3ajZoe6dGF1E6dPlvf79qy932ntWX2aLPaVmM9eTxsT8jN452ZaBsn3Lnrll3b79uNWNOj7Wt6dHE1fdu+pkfb1/Ro+5oeXVxN37av6dH2NT3avqZHF1fTt+1rerR9TY+2r+nR8mtzGMOItZ3ehk0JuXm8I4cXE2jZf007X+3cf++kNqfx69E8anp0cTV9276mR9vX9Gj7mh5dXE3ftq/p0fY1Pdq+pkcXV9O37Wt6tH1Nj7av6dHZ5TP2u7bsfd9pbZk92qy2k/GzperuZY9hadbW1np9fX3ZwwAAAAAA4Dyq6kR3r222zgdPAgAAAAAwLCE3AAAAAADDEnIDAAAAADAsITcAAAAAAMMScgMAAAAAMCwhNwAAAAAAwxJyAwAAAAAwLCE3AAAAAADDEnIDAAAAADAsITcAAAAAAMMScgMAAAAAMCwhNwAAAAAAwxJyAwAAAAAwLCE3AAAAAADDEnIDAAAAADAsITcAAAAAAMMScgMAAAAAMCwhNwAAAAAAwxJyAwAAAAAwLCE3AAAAAADDEnIDAAAAADCsQ8seADNz9Nji+8njZ5fP2Fjbbr3aPMYw99ocxjD32hzGMGJtDmOYe20OY5h7bQ5jGLE2hzHMvTaHMcy9NocxzL02hzGMWJvDGOZem8MY5l6bwxjmXpvDGEaszWEMc6/NYQz7XWNHnMkNAAAAAMCwqruXPYalWVtb6/X19WUPAwAAAACA86iqE929ttk6Z3IDAAAAADAsITcAAAAAAMMScgMAAAAAMCwhNwAAAAAAwxJyAwAAAAAwLCE3AAAAAADDEnIDAAAAADAsITcAAAAAAMMScgMAAAAAMCwhNwAAAAAAwxJyAwAAAAAwLCE3AAAAAADDEnIDAAAAADAsITcAAAAAAMMScgMAAAAAMCwhNwAAAAAAwxJyAwAAAAAwLCE3AAAAAADDEnIDAAAAADCsPQu5q+qmqnqgqu46p/7qqvp4Vd1dVW+aan+qqm6vqi9U1ds2bHu4qv5zVd0zbX/jFo/1lKr6w6q6c/p6+17tFwAAAAAA83FoD+/7F5K8LckvnilU1TcleUmSr+/uh6vqydOqP0ry40munb42ekt3315VlyX5tar6a939q5s83ie7+7rd3gkAAAAAAOZrz87k7u47kjx4TvmVSW7s7oenbR6Yvv+/7v7vWYTdG+/jdHffPi0/kuTDSb5mr8YMAAAAAMBY9vua3NckeV5VfbCq3l9V37DTG1bV5Un+epJf22KTp1bV/5zu93nnuZ/vr6r1qlr/3Oc+d2GjBwAAAABgVvY75D6U5Iokz03yuiS3VFVtd6OqOpTk5iQ/192/vckm9yf5s939zCT/IMm/r6qjm91Xd7+ju9e6e+2qq6662P0AAAAAAGAG9jvkvi/Jrb3woSSPJblyB7d7R5JPdPfPbLayux/u7t+blk8k+WQWZ40DAAAAALDC9jvk/uUkL0ySqromyWVJPn++G1TVP03ypCSvOc82V1XVE6blr03y9CSbnfENAAAAAMAKObRXd1xVNyd5QZIrq+q+JG9IclOSm6rqriSPJLmhu3va/tNJjia5rKpemuRFSU4m+bEk9yT58HRlk7d197+pqhcnWevu1yd5fpI3VtUXkzya5Ae6+9wPvQQAAAAAYMXUlDEfSGtra72+vr7sYQAAAAAAcB5VdaK71zZbt9+XKwEAAAAAgF0j5AYAAAAAYFhCbgAAAAAAhiXkBgAAAABgWEJuAAAAAACGJeQGAAAAAGBYQm4AAAAAAIYl5AYAAAAAYFhCbgAAAAAAhiXkBgAAAABgWEJuAAAAAACGJeQGAAAAAGBYQm4AAAAAAIYl5AYAAAAAYFhCbgAAAAAAhiXkBgAAAABgWEJuAAAAAACGdWjZA2BGjh5LTp1e9igAAAAAgCOHk5PHlz2KITiTm7ME3AAAAAAwD7K6HRNyAwAAAAAwLCE3Zx05vOwRAAAAAACJrO4CuCY3Z7nGDwAAAAAwGGdyAwAAAAAwLCE3AAAAAADDEnIDAAAAADAsITcAAAAAAMMScgMAAAAAMCwhNwAAAAAAwxJyAwAAAAAwLCE3AAAAAADDEnIDAAAAADAsITcAAAAAAMMScgMAAAAAMCwhNwAAAAAAwxJyAwAAAAAwLCE3AAAAAADDEnIDAAAAADAsITcAAAAAAMMScgMAAAAAMCwhNwAAAAAAwxJyAwAAAAAwLCE3AAAAAADDEnIDAAAAADCsQ8seADNz9Fhy6nRy5PDj63OpnTy+GONGO6nNZfyXUjt5PF9is+dr475vdpvdNvfXzGa1g/w6upTafvXtQl+3270Gz3d/u/363aoflzL+Vatt95q5lJ9bq9LL/f4ZtdOe71Z/L+TxLuQxVuln+1bH/Et9jN3q0cXM07n3/IxL7dF+HnOWVXOsG+Nn+4g1PdKj3ajpkb7tVW2uvw/zx5zJDQAAAADAsKq7lz2GpVlbW+v19fVlDwMAAAAAgPOoqhPdvbbZOmdyAwAAAAAwLCE3AAAAAADDEnIDAAAAADAsITcAAAAAAMMScgMAAAAAMCwhNwAAAAAAwxJyAwAAAAAwLCE3AAAAAADDEnIDAAAAADAsITcAAAAAAMMScgMAAAAAMCwhNwAAAAAAwxJyAwAAAAAwLCE3AAAAAADDEnIDAAAAADAsITcAAAAAAMMScgMAAAAAMCwhNwAAAAAAwxJyAwAAAAAwLCE3AAAAAADDOrTsAcCuOXosOXV62aO4NEcOJyePL3sUwGYu9GfMqPP5oOznqOb0/OznWC7lGO81Oh8X+zwe9OdwTvMeRmYuscpWIQ/ZirnIDjmTm9WxCj/QV2EfYFVd6PwcdT4flP0c1Zyen/0cy7Juy+662OfioD+Hc5r3MDJziVW2yq/XVd43dpWQGwAAAACAYQm5AQAAAAAYlpCb1XHk8LJHcOlWYR9gVV3o/Bx1Ph+U/RzVnJ6f/RzLsm7L7rrY5+KgP4dzmvcwMnOJVbbKr9dV3jd2VXX3ssewNGtra72+vr7sYQAAAAAAcB5VdaK71zZb50xuAAAAAACGJeQGAAAAAGBYQm4AAAAAAIYl5AYAAAAAYFhCbgAAAAAAhiXkBgAAAABgWEJuAAAAAACGJeQGAAAAAGBYQm4AAAAAAIYl5AYAAAAAYFhCbgAAAAAAhiXkBgAAAABgWEJuAAAAAACGJeQGAAAAAGBYQm4AAAAAAIYl5AYAAAAAYFhCbgAAAAAAhiXkBgAAAABgWEJuAAAAAACGJeQGAAAAAGBYQm4AAAAAAIYl5AYAAAAAYFhCbgAAAAAAhiXkBgAAAABgWEJuAAAAAACGJeQGAAAAAGBYQm4AAAAAAIYl5AYAAAAAYFhCbgAAAAAAhiXkBgAAAABgWEJuAAAAAACGJeQGAAAAAGBYQm4AAAAAAIYl5AYAAAAAYFhCbgAAAAAAhiXkBgAAAABgWEJuAAAAAACGJeQGAAAAAGBYQm4AAAAAAIYl5AYAAAAAYFhCbgAAAAAAhiXkBgAAAABgWEJuAAAAAACGVd297DEsTVV9Lsn/WfY4ZujKJJ9f9iCAfWG+w8FgrsPBYb7DwWG+w8Fgrp/157r7qs1WHOiQm81V1Xp3ry17HMDeM9/hYDDX4eAw3+HgMN/hYDDXd8blSgAAAAAAGJaQGwAAAACAYQm52cw7lj0AYN+Y73AwmOtwcJjvcHCY73AwmOs74JrcAAAAAAAMy5ncAAAAAAAMS8gNAAAAAMCwhNwHQFXdVFUPVNVdG2o/UVW/W1V3Tl/Xb1j3o1V1b1V9vKqObah/y1S7t6p+ZL/3A9jeZvN9qr96mr93V9WbNtTNdxjUFsf392w4tn+6qu7csM58h0FtMd+vq6rfmOb7elU9e6pXVf3cNKf/V1X9xQ23uaGqPjF93bCMfQG2tsVcf0ZV/XpVfaSqfqWqjm5Y59gOg6qqq6vq9qr62PR7+t+f6l9ZVbdNx+rbquqKqe74vg3X5D4Aqur5Sb6Q5Be7+9qp9hNJvtDdbzln269LcnOSZyf56iT/Lck10+r/neSvJrkvyW8m+a7u/uh+7AOwM1vM929K8mNJvrW7H66qJ3f3A+Y7jG2z+X7O+rcmeai732i+w9i2OL7/1yT/ort/dTph5R929wum5VcnuT7Jc5L8bHc/p6q+Msl6krUkneREkmd19+8vYZeATWwx138zyWu7+/1V9fIkT+3uH3dsh7FV1f+KRtwAAAZ3SURBVFcl+aru/nBVHcniuPzSJC9L8mB33zj9keqK7v5Hju/bcyb3AdDddyR5cIebvyTJu7v74e7+VJJ7szhoPjvJvd392939SJJ3T9sCM7LFfH9lkhu7++FpmwemuvkOAzvf8b2qKsnfzuKX38R8h6FtMd87yZkzOp+U5DPT8kuyCMi6u38jyeXTL9LHktzW3Q9Ov/jeluRb9n70wE5tMdf/fJI7puXbkvzNadmxHQbW3fd394en5VNJPpbkz2QxX981bfauLILvxPF9W0Lug+2Hprc43HTm7Q9ZTKjf2bDNfVNtqzowf9ckeV5VfbCq3l9V3zDVzXdYXc9L8tnu/sT0b/MdVs9rkry5qn4nyVuS/OhUN99htdyV5MXT8rcnuXpaNtdhRVTVU5I8M8kHk/zp7r4/WQThSZ48bWbOb0PIfXD9fJKnJbkuyf1J3jrVa5Nt+zx1YP4OJbkiyXOTvC7JLdNZnuY7rK7vytmzuBPzHVbRK5P8cHdfneSHk7xzqpvvsFpenuRVVXUiyZEkj0x1cx1WQFU9Mcl/TPKa7j55vk03qZnzGwi5D6ju/mx3P9rdjyX511m8pSlZ/MXn6g2bfk0Wb33cqg7M331Jbp3e1vShJI8luTLmO6ykqjqU5G8kec+GsvkOq+eGJLdOy78U/5+HldTd93T3i7r7WVn8AfuT0ypzHQZXVV+eRcD977r7zDH9s9NlSM5ct/vM5UbN+W0IuQ+oMxNm8m1ZvAUqSd6b5Dur6iuq6qlJnp7kQ1l8WMXTq+qpVXVZku+ctgXm75eTvDBJquqaJJcl+XzMd1hV35zknu6+b0PNfIfV85kkf2VafmGSM5cnem+S76mF52bxAbT3Jzme5EVVdcV0qcIXTTVgxqrqydP3L0vyT5K8fVrl2A4Dm95d/c4kH+vun96w6r1Z/CE70/f/tKHu+H4eh5Y9APZeVd2c5AVJrqyq+5K8IckLquq6LN7C8Okkfy9JuvvuqrolyUeTfDHJq7r70el+fiiLifKEJDd19937vCvANraY7zcluamq7sri7Y03dHcnMd9hYJvN9+5+Zxa/zG68VInjOwxui+P79yX52endG3+U5Punzf9Lkuuz+BC600m+N0m6+8Gq+sksArAkeWN37/TD6YF9sMVcf2JVvWra5NYk/zZxbIcV8JeSfHeSj1TVnVPtHye5MYtLjL4iyf/N4lr8ieP7tmqRcwAAAAAAwHhcrgQAAAAAgGEJuQEAAAAAGJaQGwAAAACAYQm5AQAAAAAYlpAbAAAAAIBhCbkBAGAfVNXlVfWD0/JXV9V/2MPHuq6qrt+r+wcAgDkRcgMAwP64PMkPJkl3f6a7/9YePtZ1SYTcAAAcCNXdyx4DAACsvKp6d5KXJPl4kk8k+QvdfW1VvSzJS5M8Icm1Sd6a5LIk353k4STXd/eDVfW0JP8yyVVJTif5vu6+p6q+Pckbkjya5KEk35zk3iR/IsnvJvmpJJ9K8jNT7Q+TfG93f/wCHvt9Se5M8uwkR5O8vLs/tDedAgCAC+NMbgAA2B8/kuST3X1dkteds+7aJH8nixD5nyU53d3PTPLrSb5n2uYdSV7d3c9K8tok/2qqvz7Jse5+RpIXd/cjU+093X1dd78nyT1Jnj/d5+uT/PMLfOwk+ZPd/Y1ZnI1+06W1AgAAds+hZQ8AAADI7d19Ksmpqnooya9M9Y8k+fqqemKSb0zyS1V15jZfMX3/QJJfqKpbkty6xf0/Kcm7qurpSTrJl+/0sTdsd3OSdPcdVXW0qi7v7j+4yP0FAIBdI+QGAIDle3jD8mMb/v1YFv9n/7IkfzCdBf443f0DVfWcJN+a5M6q+pJtkvxkFmH2t1XVU5K87wIe+48f6tyHPs/+AADAvnG5EgAA2B+nkhy5mBt298kkn5quv51aeMa0/LTu/mB3vz7J55NcvcljPSmL63Mnycsubvj5junx/nKSh7r7oYu8HwAA2FVCbgAA2Afd/XtJPlBVdyV580Xcxd9N8oqq+q0kd2fxIZZJ8uaq+sh0v3ck+a0ktyf5uqq6s6q+I8mbkvxUVX0giw+ZvBi/X1X/I8nbk7ziIu8DAAB2XXV7lyEAALC1qnpfktd29/qyxwIAAOdyJjcAAAAAAMNyJjcAAAAAAMNyJjcAAAAAAMMScgMAAAAAMCwhNwAAAAAAwxJyAwAAAAAwLCE3AAAAAADD+v84XLwFfGu7gAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1800x1296 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df0 = df.iloc[1500:2000]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(25, 18))\n",
    "for i in range(1,15):\n",
    "    ax1.scatter(df0.index, df0['askRate%.0f' % i], s=df0['askSize%.0f' % i], c='#0095ff', marker='s')\n",
    "    \n",
    "for i in range(1,15):\n",
    "    ax1.scatter(df0.index, df0['bidRate%.0f' % i], s=df0['bidSize%.0f' % i], c='#ff003c', marker='s')\n",
    "    \n",
    "ax1.plot(df0.index, df0.askRate0, c='black')\n",
    "ax1.plot(df0.index, df0.bidRate0, c='black')\n",
    "ax1.plot(df0.index, df0.mid, c='g')\n",
    "\n",
    "ax1.set_xlabel('timestamp')\n",
    "ax1.set_ylabel('orderbook')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:       LinearRegression(copy_X=True, fit_intercept=False, n_jobs=None, normalize=False)\n",
      "Signal:      ['sig1', 'sig2', 'sig3', 'sig4', 'sig5', 'sig6', 'sig7', 'sig8', 'sig11', 'sig13']\n",
      "Train score: [0.02136 0.02596 0.02572]\n",
      "Test score:  [0.02989 0.02471 0.02868]\n",
      "R2 Total:    0.026397\n",
      "Signal mean: [ 0.00227 -0.00538  0.00242 -0.46265  0.00369  0.00448 -0.00016  0.00002\n",
      "  0.00413 -0.00011]\n",
      "Coefficients CV:\n",
      "0.09103659943800435\t0.09044434715968577\t0.02725323014344433 \t-0.0001600945099097112\t-0.00022765249334322918\t0.018676483970011527\t0.20603788123904276\t-0.37684680428694717\t0.011183391958505883\t0.046325048112674155\n",
      "0.06652700913181751\t0.09950598189964717\t0.0311489213776893  \t-0.0005995196402017178\t0.006357835354682765   \t0.017468767041295043\t0.310413267565801  \t-0.4342187197912133 \t0.00904898919951056 \t0.052685535447884235\n",
      "0.06593132649068666\t0.09304219055401908\t0.032031189080767825\t-0.0007491876561816352\t0.004723632163234799   \t0.016035019438765452\t0.2882637681436541 \t-0.4275927941683336 \t0.008894428562627415\t0.05567884921591588 \n",
      "Coefficients:\n",
      "0.07178681175443818\t0.09292152256561362\t0.029249948394368053\t-0.0009028596906936609\t0.00397618233695916\t0.015760978221346186\t0.29000193213574366\t-0.45843096054039123\t0.00765759803429533\t0.055279602979137046\n",
      "\n",
      "Model:       HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=False, max_iter=100,\n",
      "               tol=1e-05, warm_start=False)\n",
      "Signal:      ['sig1', 'sig2', 'sig3', 'sig4', 'sig5', 'sig6', 'sig7', 'sig8', 'sig11', 'sig13']\n",
      "Train score: [0.02112 0.02582 0.02562]\n",
      "Test score:  [0.0298  0.02492 0.02888]\n",
      "R2 Total:    0.026300\n",
      "Signal mean: [ 0.00227 -0.00538  0.00242 -0.46265  0.00369  0.00448 -0.00016  0.00002\n",
      "  0.00413 -0.00011]\n",
      "Coefficients CV:\n",
      "0.09476113502855685\t0.07248486439620362\t0.025928232243480367\t-0.00028677777535445403\t-0.0008631525723794226\t0.01740849829862664 \t0.25457466449798244\t-0.25314722764594694\t0.011502496253601259\t0.04309316740956571\n",
      "0.07272677993349343\t0.08019418698836138\t0.030810106390173155\t-0.0005281619110933642 \t0.005559743268427772  \t0.0161880631311939  \t0.3220639594610436 \t-0.34802047935263797\t0.008956573110546064\t0.05224200892835543\n",
      "0.07226049978143091\t0.07772101271503397\t0.03132540345256075 \t-0.0006321958198563252 \t0.005003093864002394  \t0.014065792064213647\t0.2945810926240707 \t-0.375696821523507  \t0.007973313948886831\t0.05706570754269595\n",
      "Coefficients:\n",
      "0.07667497005149358\t0.07827844434768452\t0.02849804760962783\t-0.0008033250579555374\t0.00433642945654973\t0.013980325375164207\t0.3021352891662571\t-0.39641037906019455\t0.006671771004858016\t0.055875612175777564\n",
      "\n",
      "Model:       XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.25,\n",
      "             colsample_bynode=1, colsample_bytree=0.4, gamma=0.5,\n",
      "             importance_type='gain', learning_rate=0.04, max_delta_step=0,\n",
      "             max_depth=5, min_child_weight=10.0, missing=None, n_estimators=175,\n",
      "             n_jobs=1, nthread=None, nthreads=6, objective='reg:squarederror',\n",
      "             random_state=0, reg_alpha=0, reg_lambda=1000.0, scale_pos_weight=1,\n",
      "             seed=None, silent=None, subsample=0.4, verbosity=1)\n",
      "Signal:      ['sig1', 'sig2', 'sig3', 'sig4', 'sig5', 'sig6', 'sig7', 'sig8', 'sig11', 'sig13']\n",
      "Train score: [0.02647 0.02847 0.028  ]\n",
      "Test score:  [0.02722 0.02433 0.02801]\n",
      "R2 Total:    0.028267\n",
      "Signal mean: [ 0.00227 -0.00538  0.00242 -0.46265  0.00369  0.00448 -0.00016  0.00002\n",
      "  0.00413 -0.00011]\n",
      "\n",
      "Wall time: 13min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.02722, 0.02433, 0.02801])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "signals = ['sig1', 'sig2', 'sig3', 'sig4', 'sig5', 'sig6', 'sig7', 'sig8', 'sig11', 'sig13']\n",
    "\n",
    "model = LinearRegression(fit_intercept=False, normalize=False)\n",
    "plot_regression(df, signals, model=model, plot=False)\n",
    "\n",
    "model = HuberRegressor(fit_intercept=False, epsilon=1.35)\n",
    "plot_regression(df, signals, model=model, plot=False)\n",
    "\n",
    "# model = RidgeCV(alphas=[1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06], cv=TimeSeriesSplit(n_splits=2), fit_intercept=False, normalize=False)\n",
    "# plot_regression(df, signals, model=model, plot=False)\n",
    "\n",
    "# model = LassoCV(alphas=[1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06], cv=TimeSeriesSplit(n_splits=2), fit_intercept=False, normalize=False)\n",
    "# plot_regression(df, signals, model=model, plot=False)\n",
    "\n",
    "# model = XGBRegressor(n_estimators=150, objective='reg:squarederror', booster='gbtree', learning_rate=0.04, gamma=0, subsample=0.4, colsample_bytree=0.5, max_depth=4, reg_lambda=1e3, nthreads=6)\n",
    "model = XGBRegressor(n_estimators=175, objective='reg:squarederror', booster='gbtree', learning_rate=0.04, gamma=0.5, subsample=0.4, colsample_bytree=0.4, max_depth=5, min_child_weight=10.0, colsample_bylevel=0.25, reg_lambda=1000., nthreads=6)\n",
    "plot_regression(df, signals, model=model, plot=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sig1', 'sig2', 'sig3', 'sig4', 'sig5', 'sig6', 'sig7', 'sig8', 'sig11', 'sig13', 'sig15', 'sig16']\n",
      "0.02646978349129614\n",
      "[ 0.07526  0.07994  0.02562 -0.00059  0.00334  0.01196  0.29502 -0.22311\n",
      "  0.00589  0.05629 -0.03086 -0.21938]\n"
     ]
    }
   ],
   "source": [
    "print(signals)\n",
    "model = HuberRegressor(fit_intercept=False, epsilon=1.35)\n",
    "model.fit(df[signals], df.y)\n",
    "print(r2_score(df.y, model.predict(df[signals])))\n",
    "print(model.coef_)\n",
    "pickle.dump(model, open('python/model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sig_test'] = \n",
    "test_signal_full(df, 'sig_test', signals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
